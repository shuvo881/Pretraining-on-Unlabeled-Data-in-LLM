{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6718adfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:14.325524Z",
     "iopub.status.busy": "2024-05-21T10:05:14.325144Z",
     "iopub.status.idle": "2024-05-21T10:05:14.337141Z",
     "shell.execute_reply": "2024-05-21T10:05:14.336227Z"
    },
    "papermill": {
     "duration": 0.043644,
     "end_time": "2024-05-21T10:05:14.339048",
     "exception": false,
     "start_time": "2024-05-21T10:05:14.295404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,   # Vucabulary Size\n",
    "    'ctx_len': 256,       # Context Lenghts\n",
    "    'emb_dim': 768,        # Embedding dimennsion\n",
    "    'n_heads': 12,         # Number of attention head\n",
    "    'n_layers': 12,        # number of Layer\n",
    "    'drop_rate': 0.1,      # Dropout rate\n",
    "    'qkv_bias': False      # Query_Key_value Bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61695c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:14.397506Z",
     "iopub.status.busy": "2024-05-21T10:05:14.396888Z",
     "iopub.status.idle": "2024-05-21T10:05:28.059369Z",
     "shell.execute_reply": "2024-05-21T10:05:28.058271Z"
    },
    "papermill": {
     "duration": 13.693585,
     "end_time": "2024-05-21T10:05:28.061779",
     "exception": false,
     "start_time": "2024-05-21T10:05:14.368194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\r\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\r\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tiktoken\r\n",
      "Successfully installed tiktoken-0.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd14e92",
   "metadata": {
    "papermill": {
     "duration": 0.029129,
     "end_time": "2024-05-21T10:05:28.121777",
     "exception": false,
     "start_time": "2024-05-21T10:05:28.092648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "835b19a2",
   "metadata": {
    "papermill": {
     "duration": 0.029025,
     "end_time": "2024-05-21T10:05:28.180187",
     "exception": false,
     "start_time": "2024-05-21T10:05:28.151162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Normalizing activations with layer normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa1f07",
   "metadata": {
    "papermill": {
     "duration": 0.028753,
     "end_time": "2024-05-21T10:05:28.238307",
     "exception": false,
     "start_time": "2024-05-21T10:05:28.209554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A layer Normalization class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fc3444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:28.298587Z",
     "iopub.status.busy": "2024-05-21T10:05:28.297641Z",
     "iopub.status.idle": "2024-05-21T10:05:31.953988Z",
     "shell.execute_reply": "2024-05-21T10:05:31.953165Z"
    },
    "papermill": {
     "duration": 3.689039,
     "end_time": "2024-05-21T10:05:31.956357",
     "exception": false,
     "start_time": "2024-05-21T10:05:28.267318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        \n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "attachments": {
    "251c4c3d-22ee-45d0-81c6-7029e525dbac.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAA3CAYAAAAmN+bLAAAAAXNSR0IArs4c6QAAIABJREFUeF7t3QO0Lcn1MPCef2w7mdi2JrbtZGJzYnNi27Yntm3btp1M8r7v1zN7pqZfo/qcPry117rrvvu6u7Cranvv2mPXrl27qgIFAwUDBQMFA9uPAdR+j+2fZplhwUDBwKwY2EYisY1zylzfHTz1TAwt9rUO/JdlWSzatb5HUXAXj+RF9VAOyKIwu4ntlt2wslVbK9Sv1WBWtiSl4x2OgQ06Bmsz1LUZyA7fu2sw/W3fCts+vzXYQmsxhM1VcMsOXYsNVAYxjIG2rbqt23db5zW8yuWNgoGCgYKB7cRAoesrWtdFIn6Rba8IXaXbgoEUA5ur4O7IdVwtRVpt7ztywcuk1xgD5Tys8eKUoRUMFAwUDBQMFAwUDOxYDBQFd82Xfq2E6LUazPIXbodPf/kI36YeV7x5Vtz9Nq1kmctGYaDs/LzlKnjKw1N5q2CgYGBTMFAU3E1ZqTLOgoGCgYKBgoGCgY3CwKYqTps67o3aHGWwG4SBciI2aLHKUGsMbJmCW45g2dfrhIEN248HDneKUU/RxjqtZBlLwUDBQMFAwUDBwI7HwBzMvffTOdrd8WtSENCKgS1TcMsqFwwUDBQMFAxsFQZSwacIQVu1tGUyW4SBcja3aDHLVAoGNh8Dm6/groyorqzjzd91azmDOdZzjk/XEhVlUAUDU2CgnIspsFjaKBgoGCgYKBgoGCgY6MBAl6ixhgpukYrKLp4aA2VPTY3R0l7BQMFAwUDBQDsGCscpO6NgoGCgYGC1GFhDBXe1CNma3guH3ZqlLBMpGCgYWE8MLI7MLq7l9cRkGVXBQMFAwUDBQD8GCl8Ys0OKgjsGW5v47lafh62e3CbutjLmgoGCgRkwcDAlKzQtB31//etfq89+9rPVuc997upIRzpSVVUFbzl4K+8cjIFD7pjV7Z/V9Vx2Q8HAdmOgKLjbvb5ldgUDS8dAYdhLR/nO63DkJnvzm99cveMd76j+/Oc/V3/729/qH0qSv3ft2lWd6Uxnqh7ykIdUpz/96ZeAy5GDX8KIdu9ifcf473//u7rkJS9Z/ehHP6rOfvazV/vtt99KMFQ6LRjYcRiYiyzM9fGOQ3WZ8PwYaCi4ZQOua3jAz3/+8+pxj3tc9YlPfKI63vGONylT1+Y973nP6mpXu1p1pzvdqTr0oQ89585a/31EwN1jjz2qIx7xiHPOdXs/X/9VnB/3r371q6tXvvKV1Xe/+93qiU98YnWpS11q/ka3ooXtWX1n/SxnOUu1//77d67M0Y9+9JqmnvzkJ9+K1Zt3Eut8Lj7/+c/XvAqg4d///ver//u//5t3yq3f44ff/va3a9qwHOPH9NNYpOww/WhX2+Lvfve7Ci041KEOtfCBLLOvhU+mdLBjMPDLX/6yus1tblMd97jHrR796EdXxzjGMQbn/t///rc2Kv/rX/+qfvOb39TGyR/+8If1z09+8pPqZCc7WXWDG9ygOuMZz1g973nPq174whdW973vfasrXOEKg233vbBUD+72iExz4fygj3Px8YUvfKG62c1uVv3+97+vTnziE1d3vetdq2tc4xrTDKKqqmc/+9nVIx7xiLo9IV+veMUrqsMe9rCTtb9uDb3tbW+r7nOf+1TnO9/5quc85zmHGF7umqzbnMp4xmGAsmMPvOY1r6mF5Kte9arVve51r+oEJzjBuIbK22uPgb/85S+1hzZASCs6d9KTnrQ61rGOVYe4XulKV6oNhzsdNuFc3O9+96te9rKX1UvlvH7yk59c2LKd7nSnq/7xj3/U/PCpT31qddnLXnZhfS2i4UXLDosY86rafNSjHlU997nPrewv8tYiYZl9LXIeQ22LtqDAMBigt3jtzoLtkyi/9KUvVVe+8pXrZaTkvva1r60V1C540YteVD35yU+u9Zc+0CYae5Ob3KT6wAc+UL96q1vdqj6Ps8JSFdxZB7mTv2MtwVT/8Ic/VKc61amq173udVkWkzE40/b1rne96hvf+Eb92S1ucYvqAQ94wJgmNubdr3/969VVrnKVCuHdc889q3Od61x1Lhdr6qlPferqbGc7W3XLW96yNiQU2F4MEDCe+cxn1hPcd999qxvd6EYbN9ntY52LWwJn/otf/GLdwR3veMfq7ne/++I62+CW1/1csP4zTIY3niJyhCMcoaKIMlJMLUBTpB/4wAdWPBBHOcpRqne/+93VCU94wo1Y4WXIDhuBiIxBvvSlL63uf//712/aXyK7vva1r9VywhnOcIbqAhe4QHXTm970wHzvjAZ7XllmX/ONdPjrX/3qV7VRgGdOqsc///nPg1JApH+QKf0fuPzlL38Qzx1uubyxrhiwzvvss0/1xje+sR7iWc961uoNb3hDa+TnV77yleqKV7xi1lSufe1rV4997GMrRrkb3/jG1Z/+9Kf6O/vr0pe+dFYbzZcWpuD+9Kc/rT73uc9V5z3veavjH//4Mw1u3o/++Mc/1oKMEKM3velNkyuG847vgO/7xdQb3vCG1Uc+8pGasL71rW+tTnGKU0zTbaMVRIgXC0EiJPBsnec851lIXznzXlTHt771rat3vvOdvc0TmJ70pCfNZa0nEBGoCV4HFEFph0996lO1h+BCF7rQUsKiFoXXTWr3M5/5THWta12rZsgMO4T6IWAAecELXlAbRC52sYsNvT7J82UosA996EOr973vfdWLX/ziXivsJBNaYSOiUnjsgVCoiFhZ4ZAW1jVhc++9967bJ0znRuPMci4WNomOhuVJO4dA9M2znvWsSsgyEN5m3hSUPo/C2DGTHYQqgwte8IJ1hNMmwLJkh03ARd8YKbHW9de//nXvVE5ykpNUvFEcDbPCMvtKxxjGPQb8eaDZzkte8pJsZ8iJTnSi6uMf//ghug8etxt/bTA/oaz/+9//6hSSMGI1+SPjF1oglYDzYieA6BVezuMc5zi1zHrmM595mmlnCB/4adBCehbDcROEInPQ/f3vf6+OetSj1sYivxmQDne4w9VGpK9+9av1ZxxLYWT6wQ9+UBtEfHfMYx6z+tCHPlR/NxYmV3Ad4Kc//enV0572tNrKanBvectbZvaIURQggVYv1IGbmwX1HOc4R3Xxi1+8d75PeMITatc4RPLcjc0tZZ3S35jcG/mswt5Oc5rTjF2L3d7X1nWve936/wnhhPFFAk9mhD5f5CIXqRCvbQK5Wpe4xCVqQhnA+CI/zx759Kc/XVlzQCh817veNZNBwb6//vWvX1Fegf0g/JEHgPJMoUXQEeSwUhmDc1LgAAxk0NeZUXWd61ynDmvEBN/73vfWa98HBB/Gn5/97GcVofHhD3/4zH2v24do6Pe+973q5je/ee2p2laQ/yMs2W8Fip7//Odv61Sr3/72t9U5z3nOen5jrN9jz0WKwP3/s3+135v2q636hBr0jQGJUiD0jKe1z9CXsxg//vGPa57/n//8p+ZT+Lu1/M53vrPb52guA62cejRfXuU8EMqiNuRqK27VCYskXpmTWLbskDmstXxNDYZ73/veB42NAsWRQFngJCEXKUgHTnnKU9YG8naj0fDCT9fXAcMlQ5DTpGBc5jKXacUvXudsm9eHP/zhVuVv1nbghYzKUwcOc5jD1IoIWQeOnNnw4PLk0Q2aMMRf8Wg5n869NqUlON+UJLn3IhDRG+2QvYRDS7vb9noaHIiMteRJQNd6/etf3ymz4n1CgBkp6FL+PvKRj1zrN6c97Wnr3ww9ubRS6s+FL3zhWkfyDZrTVtNGX344B5rnhkMt0j6aSjId8rGPfVwtDUofu93tbqvqwigaMqmCSyHgEeC9TYGHYIzViwXa4mEkUfmybVa3u93t6ol3weMf//jqKU95So1YCz8GFGZwQCjsuYpOFL9ASBTp4L2eB1ijWS7kLrz//e8fraDP0jdrkPkChHyMcj9Lf8v8xl551atedVCXQlRZiQIIZA6VYl6AJ8A6joX00OZ+S/hjhCmwWAwwlFFWAfpwzWtes7dDTJVwgB6BbVNwGbJYx9E6xR3WHawZITPWcMx4I3pj241JQlOD90g1kXIyBGPPRdoeC/ztb3/7eh91AWOSKIF5IpB4CFTDJky95z3vqfO//E0wIjN0AcP2XnvtVSvZ9nsbkA8I//gfT3AT0Ga8Ao8gkBGglwvDylM6nl7ZYVxTy53mknuzniJyeIzA0Y52tDraLy02RxG4y13uUoenA/8WojkWpu7rm9/8Zm1Ip9z1Ge14xURyAB7oZgTSFO1QMikvTSOWIkTPeMYz6r5FXDSV8Bz+msqkuTg3Zx7Bg2DL9rw1E9L75z/9qXYGBPCSMzI260kwYDAKMj72AVqJRqK1vUa8AxtRDOrBD35w/ZfoGvmzYyCVlR/5yEfW+zmA4n7Ri160ws94qHn/c6ORoo1JFFwKLXc1BtEEuU9c531VDh/zmMfUyhSrjIPC08ZzOwTyJD/2sY91vmaDI0qzJCpjeIo5AYJfjjUIo4+qXwRnwtiswArPAg0PLNWzFpUae66Fc4t3R4xVqrR22wAEIF5/FkfedXvH4WwDQmF4ryn7wozHAOErhEoeDH0hLL/4xS9qvDaB1QvTJIAXWCwGYm2FMDIaDVXLTAvaGNm2KbgX3Guv6qc/+UmdY8a7sO7A2EAZY0xkfR4Dzlgwf9Ea2wqMs+c///nr6d3tbnc7KLy2b75jz0W0xXNjTSgBgIDEmE3QQmsjisUzhgnemFkqHutHji36SWBOq2syVEaaAe8RAZ5Xl/DUpLc8FeQB/DRCHUVm2P+AICUVqC2tihLvmfEz2s+jrC9y700lOyxyjOvSNsPl1a9+9Xo45AKpK/ZHEyhiIhEYOnjKfDd2H0/ZV6qUMvRQyrtywxkD0cxjH/vYdeQSL2vAVO10rSclDA0wRh6+ZhRlDn9lWBLFCXgMowqv8NU2oJjxVJK9thFEXNmnDBvkF3oC+RLdB2icwk+MNQFp5XlVj+0V/FMEIeNOm4HwQQ960GCxNedCeh3ZFs2nA46JlE0VXOkml7vc5Q6xZGm+Oj0RrxkDcyu48kNp+xTTFDAaeSuspkNCJA9lE3yDSdPghYqwqkZIAmRKQj784Q/fGdaJ4droFo7gFgwsFzn3uMc96jxU85CbpK8cwNwt+rwCY1hGbELEaazlImesXe8EI7dRre+mFNXom/Pb3/726ra3FeJQ1RXa+oQTBFSohr2jVPlYxdOVEmEYULE5KrhqjzAllEYBBnucIGUsQpcLLBYDwpcwA4zhgJCX2/V2KGT8Dne4wyHe2TYFF43FGFne7fNUeIAvdAcNbzKexa5Ud+vSNFhyRVaIsBgDPH0Yv3PnWqixAuqYvlb5rrBAQgdQOI9gTgBCe0QkMZrygjJKM96NPRfp3CiKQjgBrwGBhIAVQKiF95/+9Gd1qNmYkOm0H2GQ2mpLnUlvAUi9AOjsBz/4weqjH/1o/ePcBwh1RqfhQRgqo26kp6DXijkekibvqr797e8cZPzladDXOsIqZYd1xEffmMKwI+wVXemjCYzdofyKHFBcZwxM1Zd9jB7br/YomtaVe0mBIQc78+Q610EGTNVOFw44qsJb3FbYL4e/kqVFEfrd9FLjVXQBIbJkK7Iyz/s2yKtdOMWrGSysPQUWH4Qf68yAy2gPrLn82AgZlpYnLUcOtlSdFOwNBkH7KI3iIvvQg4YgVUJFzHJq5kIaOaSgX/Ct+N66M2qYNznZ/MYUEpxLwRVywHIa3lbCEsWTMsp6kjsQA482KJIEKj+sqV2AKSNGXQQpDg8GxnI2xqoAqbx9lBChPg972MOy1suYCBQ2k43EqjYrRNVPoVUvf/nLZ21mpu9Sq0qa+D1TY2vyUYS5OPhC34eAACM6wOGK8J6hb+J5fIvQEsoKrAcGCLvoExChIXWhCwi9hGm/U1i0gqtmAIsqz9vUFmhMAiMj2BA+WO95otKc9DZ88JZFmNmqV1IlU0wuN/Q2HS+FhJUYUMr6+Muq5zmmf+sYhjOK+2c/97nqi1/4wmAT+Br+NuZcNBsN75D/71JeeW3leINZKlhbb+vOMEHJwGNTiMrPZAFXWLQVI+HJxddU6QwhUKi6lBXGHV5Pe4PAiO/juXhvE4KPMPzwTPHmrRusUnaYAhfkKIoY5U3Y4xjZbUz/qWGH8TvNw21rB53k5SUfGh+FEeREyU3Vl/7wMGfWfrdnu3JvvUvWufOd71zL4pHuFnObqp0unAe9NU4GJh6+gFz+yrkUaUSzePDG7Id1f5eOxMCL7jgbaFTUWjB2+1KIMFwD9Iuxa8g5hi4y2KB9YQS0X0S/5tQSYjTl0GNwYGgR5ZILKW8QXUXvakIaBq3AoJoKuTCTgmtCrL+snIDLW1XKNJ8xdwDeC6bhILCiTXEXJe8M79ksocLBUINA5MSie5clKd6dRTFKcYaJwzPi1byrdQxuZ303Co6wyjtQucaKMf1hDP/5979rqw0G4LcDPG/ucnMMkuEdHPiUL0BYGoLI12Ws4f3NBZZEh9zvbQrxzp3/Or9HSZMTBIbyywnELJqUQgSVp8qaLlrBZfGmfHZVJcwTp3ZfBYK/sxWhpF3r5JyLqLHvVTz0G/MaKsS1rHUPuu4MR+5Pbt9pxc+xdSGiD0Lul7/85epb3/pWbSzAs3gDw5ucI+zmjjfnPVZv+WZtqQ/p98IS8RTeSeuKRoWBZ8y5aI6JUKL/UPjahKn0qoihuhnN9vEF3lVheV3G5jB68GQMVcjXvkI3hGUg1C9qLvibEIlfKJKzW+TZrqr65KcOKNgDmjljOeu1jHdWLTvMO0ee9/AykTGbHqd524/vKXxRbXyIH8Q3UbNg7FWKU/Ul+izyHCmukUbXhROOIrQODkNe9+5U7XT1K39SFByFCT9hsOVNJIdJRZSp9drXvmaQv6bRcMJf26I9p9oP694OPUCBSwYf3ljRrU3A30W74FGgSwal1IpspWAyjqaA15OTfJsLIhatVeyt3PQNSnVEFXStb1ogkvGOlzgXRiu4XOEYShRdERIgcX2esvyRQ0NRjjLkuRNoew9CMG8x+rn5s2k7EUoi5AFzzg1lS0PD5HXEgs8yF4IIRruqasaKe6lcB4a8XUPzo1g6jM2D1PUdQcVBTq1TQ330PU/Dk3MZGe+GveOgxqXTOWNIvSGIRFTBzvl23d5ZtrC+6PljCorggcFKqDGYXVTKXXX+IOF30QouusUSOktofB/+CPHykrqA18tzkSe5VRQXtV6UtVAymoY1Ah16NMudiqzUcZWBc5oWkmmdS3IA5DDpF/3g7UtB1JH6C2lu21S4wcsoUsYrLA1P4tmn9Lm7mQAbIcJtfRIo5blRaLuMFDOdi6QzSj/vQVf7aQjbbsVfBhBFtpALZn9SEto8phFm31RWm00bI8GPUcC9jaDt6pKhtWN05jVfRXTV0Ng8X7XskDPGvnfS0NZZQoFz+w85T6hnKARD30Y+6Nirxqbqi1xJ9pbaxFPXR3PI6mQo+75p2J+qncAXuiiSgsxNuRUF0QZtV76g9138NSJEzDfN5x9ap218jnaiXaK8+sKAOdrInYywDAJttZEudelLV9/+1rd2QxPjJwWyGSUzhE9GKXSYQbLbOL97K2SOMDDKb++qtO+GB0UKPRfWnGtwH6XgGryDLVEdEMYoAXHZs8PGupnr8YzphoLbpkzY/IQHh5rVwY8FdGgpxHJeHV4J9AFRin0sMuL7CDGVY4HA5kKEg3h/rKW62Udcf+Bgw3euB5UQhtDYNF0VI6MvIbjCEGwYlcr8HQSTMC9fkTA3i7cknQ9hNfJQc3HJgs64kDvvvnbDG0sQVawgJ+QpKnYSggmXuRB5ft5nHUMoFGFjuBF6KjRH6LKS+c1Kd7l9rOI9gjYPoP3IA9LHWM2R91N4EcVA+FeEKK5i7NGniI7Iux3jfTF3hB8I6woleeq5uE5BP84e5QVdy9mrOePgbdQmizqPLPpibwsBVFiOgBGhmznthe7HeIXuocuEGjSZEKPS7JAVN+4tRKeixoHx8VAQOI1PHQQFSgKiKMksNQ60FTlFaJ3ib0Mg7FYYq9DfLnDG0dFcQ+hQn/EcbuGiq5AivIhQwoOFrPEkwyUDBQ8Tfp1jkJn1XOTOI62C2hX629YWAd181PfoCklPeYvoB3TV/uMtEn1BWUJ3/baGcBpgvSj3Q9cNNsdG0CJw8fCicTxS6wSrlh3mxQWBHK0CBGApEkN1XGbpM7yxIscoDjkQBsjc+9Ojzan6YoB0Hsi2Qjf7ot1e+MIXVQ9+8IPqIVCG05SXce0cXCm32Y62nTPe2qFUF7yMbO3spPJDF38lN2kXRJoMHkkupAy5esY5l2ogymoKWTHWa9HG/Ww5fVdVfezjB8jp9AByOoPmkDEVnugAomHbZC/4auNp9CnGD3pcqlPlnA0OMY6x3EgabfLe8uLiX4yGXUBZZ9QFbdW4u74bpeCmbmgKC4HBQSPApmGcJshyZHM6SAT5PgIVYQiUGps/7rNSGIPVNi0O0TaRJrEJq48KbnJuxgJEQujY3LMozhSEWXGPWYEHJ3JvWcCFPOdA3GtpXcTCtwmZBCYVnsMLr13KrI2WCmlxrUZq5Z714BMkurzzjBUOrjC0sPyNDUXoww3LvqqpvBlC6nIgrPT2EotZDlBMGEUIXYDSwBjTLMDmGYFeaOCYfIKcMSzqnbQgRJf1mkBKIZAnEaGwGBC60ZcnNN2Y+3cnhSrCMsfshfS7eQ1X6VwJBgxomDX66HwQxFNwHimNKshSRucBVW0xxtT6Ke+MQXCsgmscDGNov0IfTWDEkS/Zdzl7MMQIPRUC7ryl12WJ/KBQBOy77771HmtbP8IXBqtvSlVTCEg9lbwBbZVy03mkRWXi/wkArOP69z2exas6lXKb7uD0eg/946OEDjSScBdAgMEvUmMIvFHschTcWc/Fbovecvy0LXz7v/vvXx3xSEeqeU5uQb2IohEdJsyyzdiT5ujlng2CMDotzapZqIyQPrSWBLGgZ4RI/GUemJWndvW5DrLDGHygI9Y3rjBxjvHNFKw9OUThG3LdvJDWS2kWX+pq25jItfbImOisKfsiBwae7FP7mIEFjyB/MC6TNzid0lsbml61qdqBK04oigovrjEwIpHpAL7Cs2ecaFJtrGxs+C7+GiG52kFn1UwQJQmfTcjNN51r30x4UKeU02eZk3QdhvpYp2YbcbMHPpprOIhoG23lGpDDmdjlaU7HFUaZMWmn2QouTx6FlWWAAEEwiyIdQ/dUIU4sCRKWCQZiu9OE87jOp2+hHGJWMB6OsLwTqDFM+XHBqHgj4kqfWaonGwPvgHDaMQWWHDqe61DQWFvmySVOQ4SFl1EwcjZaKKXmoZolhS7c/gRqQnKap6Rt1ddYfZsQ1Sn1C69Dyeq7r18+RaAQwR2iTflLS5zPcoDTb8J6mqusptYiueUUuhxA2O3xtnw4uJPPiOlQ5gFBj2FoyNOV03fWO/nLsVtzPN8MNsFcmoIdjy2vaBijzI1wTQFaJw9HGK9MkMLTtu+bk3e/Z0RDjAm/GVqTUC6H3ovn2WHVuQ1WVV07wTmniLKM5wIvC1ojJA19R38pf2izPSAqhwKI6TXv0o5tGNf2hBIbleubY0iv6opQa3wAjQwwB5Er4UVgEHCndQrSHqKegaggQlMfpLmp3nNOXQE2q1edIOccoQF+tMPbGl5vnuDwVhNUeWfwW4q685VGRjEGGh9PAHrDSBzXnRirsyrvOreGw9hzkUtK0tB4hoHIgR/aZyIORAGgN32Vl9Pw57Y24ZOCTIASEWCPkkHaCoyJVHIGRDL0GWbsMQZ+PCu30ujQfKd8vmzZ4RKXvGS1xxwTCGNMThP4CgPYkBFiqK30ruhcZTU899oeuokh7X/Kvqyt20nSSIShuXpOnhJNFbRrqnba+uYQcLUl4HlMq6q3vd/FX+XJixZrA95okRroacgkY+hLDs4W+c6Ucvqs48S7RV6Rd/0w3DGy4zkBzqa1zJHh8Jtw6rVVRG4bZxhacoryimZy7hiZIsVkaO7ZCi4mw3oOeP+ispm/KZmEE96HoWIX3uetgDQKB+ApJXA0gWCkHLrQI4pYjoIXVl/ClQq2sxBCggWixMPAypsDaVjN2Epibe07tOZOsQS5VUNZGRkQEA1AWUeYeXO1wYsDWNQUKejzIKaFCHItMjm4YjzApByoCDs33hBOEWEWJF5clsE+YSOnv7E5U9ZciXVKqXmnIZJD/clfcPh4owj7BHGGIWFQmDMLp9DTuGeXYsBzvgnAMxtexCh0QGmn9EUYdyi2zs7YEJdl4EBlcwICyPEyes9ejWtyHvjAB1U3v/nNJhkqQ1PXFVQEkr0uuFd12MMdtvZmsITzzAyFJo0dGDpMIEFbg2YMtUEBYNRk/bX+lMs0/A1zE0oM+vb3PvvsU58V1neKB2U4aBZlLoSb1KgQSmekszhPaERaQCXG3wxloowwFNq7wrOG+AkFhrco5U0UG/ShrcJuF94IYYRoV671hfGl1z6kZ62v8jCei/8SFNKUh7h/kvdEiPUQzHIuhtrEQwlIcvIYLdGIHKNveufoUJ5r6uW2Z/BuvJ8yKyoprskYGqvnYQhtu4+x+X0YEMZ4E3LGMMU76yA7jJmHHOs4+83v9txzzzrqhkInMorzIsKXx/TRfJcBKa75yTFaOrf6RjfGhGDqd+q+eHDhS2pBXG01hIu2VKup2mn2Tf6kTOfWLzkkf33gQSG15EQ0W7QKBYuhyl6gD+AXAG1mmBL1CdC6uAN8CCeLf95tBpxSTp9yHs6Z6Cb8p76S5/87Ak6y55413zz60Y5e9Vmy0HnXzoGcyBZ9OUvoVU5R3jDGj6mbkK3gRjiZwVMc2+6a4oHzzEBCWHKwbEp/24yQACieDigFILR4VlUMidBECG1a/tOFbNs6aSn2Md7X5gaJ+PQ2L0DXZuLli/LcwqynyDmk/LHKs7RQtljxWToWF/YQAAAXEElEQVSGQBgHIhPFUAhOvN2AskjRzQnzIZDxwgGWHZ6GWcA8KNNyKjCK2AM5bT30YQ+rbrz33jmvdr5jDuZifwlp6xNs4Q4BtZcw0jDqzDWAlo+j8qdHkas7dR+LaC+IjLYpW37iwnV448XNEWInG1uuKynpMDyH/oviSmnqM4TJeRElAngJpURMBTxGBPooeMRrRTHI9bzNOw4pHDyduQouxszrzUuL0TCcNQv/pNZp42Nga6v46HzFxfBhhSecyC1jKAnDFO8iAyuIMGP8B721llEnAS+hpPAeg2blUPRcbi9hiQCWA2gVoxVlOQ2No3jxwHfdP6lt38Kv+bQpts5OM0SMAYmlOnL5KeMU5Lx72A8+DFFEJlfBNd6x5yLFH+80Hs8oEGfJOrgVAYy5HiiuFyEL8AD1XZdFwUTTc69/67vTJfZbToG3wO8ic/Jz9mfXO6uWHcaM3Rng/TniEY5QC9P2kVxqkHvrwZj+4l1Kkr71lXoK21gKQxyDHPBujC+3366+2r6fty9thuGHMwmPk5M/tjbOLO2k9+4qgMd4MQTz8lch7ugA+jw2rXBobIt8PpWcvqgxUnTtG3odBw0+3pdqCv8M8SDHSJiuO2Mk/aYPQlYREYAv5EC2ght3Zml0SCAXPqXaHFd3mkPF2q5oQFQXZp1RFVNYJ+TwJIRXN2fwzXdSj6N+Zs2BpVyzaBPcePCGrMBpbhfhieA19E3u/ISSCPPkGZfr9ZKXvLQ65zl3vyuq2R7BOa42iWc8ikK6ckNi4/4pQlZciZE77vQ9QhuLUC4IqTZWgjTDyrwe3DT0EfPoqs4Mx/a5vG9z5nGY+i7SwEF6wfXYy7Fz8biI9+DIuW3edbaOoXpd8+ddZ+CJnHB0Ak3qCj1NozNyLJPz4F34JOWRkW3MmZm1z/RuWDmbTUUfE3YeI0QpvLPyeKU/MEamwNpu7HAcwFCJjjUNS83IHSG6lNWgncHQUuUF4zRmob2U2bhrHCPmNTb+CGWynoyqlGXeH+feuAibcv7GAPqHp5hHGh6IRlHemoZHyi0emOZUi2igZIuqoRgzuBHM0IKA8EDIS0aH4IKyMhbiLtQ2wcEZFpLGI5IqzmPPhTF97/vfrx76kIfUBsS4y75trOatcAlBqQ+k9jAgMQjIEYt7q7u+saYMuXK57It5IAyhQ7U74M9688y5/iQiQubpexHf7i47vCTrZoIpZId55uOsRerI2KrbY/plpEKvyFWiILqMSIx6lESGR4ZInq2xkYHL7AsOIu1PASbet1nh4HbOWr3lLcMFV8kFcT8wLzOj9xBMwV9DPxlbFHRobIt+vuqzNjQ/3nW0VV73kOMOn2KgB5RVvKcPGNajRlKOtz9SYccUmMxWcKO4hwEPVdXFAGxsApNkaopSQFoUguLGim/AIDduuwtpacnpLq/B0IJ6noYODl0ATsBi2cPcET1zbfNW5PTb9U66EQibhLyholNpxdBod6wiJaeBR54HXq7XrJDeZaYNgqc2EX0CitA63mGK7Kz5bX1jS4vFCGGDmzZIi6iNF5jGuRLTsKV5DTuzrsss3wlx570gIAdQGOQmjmX6s/Q/1TdCu0Q5xNVVvIToR5uQk+4fe2TM/XBjx4tBE+6Xxagjz944MdvUmEQ5I2hSxkKRjGt6Dhk6esDepyARNNAMAJeRz9O2xyMVJN4liKUXy8d95KnHtUlLfNs8q5grDygQ/i9MOr0Dl3KMTrddKj+0Xs6tcGh4i7A431C2eXSj2nYa8ou+yf/FC1MLeDM0M/XaR6FE9D4tujU0vngeSn5bOCUlWmX5thScMeeCp81ZaBYE6hsjjzIjUVsFa0YI51CtCMIROt0XbcMojvaQN7ruyM3Fl/fCgz109ijhcRfumKrQY8Yy1burkh3mGb+CkFG4a2y14jH9poZ3RgrGiibYY+TduGplrAwV7S2zL31GNELXPai5eBrbTupM6Lv2Je1/Cv4atJTRjmFwU2AKOX3Rc5WuJy1n6KqmkJ9FJomU6nPyifpj7IwoU3yOx7irLgYvMplDhMCYaKBsBVe+JCtWhFoJ42E1b7qshaFKDg+BSH5UWHQsBOEgCAkl1ISiOAZiJvRMmFP8YJ4Ynt8mKaQkChHZzHKibG4ISgtaUJr1TWBq3q2kHYiNNsWNpyHXLPTyLTBw8zN+Ibap8sXyh3mk+U3GISxjEZDOzTiMidesrfATZdTcm9Xm4BpDjtyTvnGmYTLWMxj6LHMjNLGO82oggDw8rKbLAsYHh8M+AoS7uC7G354LvXXdBuAxIhj33bXlMMrH4YVK7w0NnA8p6umdnCztIRhPgZOusc3bNiue/d0W3ukMy82fWslFB9ASuVhj8h5z5uoM89bEvqAMsCg2w05TZWWeyJCcMbGAsoTOUtU4p/3mO+ncmnfDhlKYFqCK6BYGKQpohCfzuvCgxl2FFA5hfFI30GzvUSrD0+mcCDWK89JGO9PqmjyE9kAaIm8uaLezlJ7VtNppeNgYXJsVqoXSS9/AkI0D86TAUkR5A/siRyjzaL8w3KgibQwUcDQhPd9tOX6pMTbWxFoEfkKw9AydGZt7HQXMKNcUhhTQPulBu4XBH2ijyz0XqTCLp+jTvrVH4ipB/LPp2cWPKfxNQ1G0hzegicJV+4oXpcV7plCE0iJkaFxbYRX0SGSUMxph8lNcYbMomm3dly07zEKH0m/QY/IXY2pOFfBZ+0MPnHUGEueLgyWtqo3fMQLFXpZ2xovVBdphpPMbDUhlgKn7Gpqzuh9k8aFohKnbYZgi7+EPXbdm9PGgJn9lIB1Kz4gwczpKms4yNLec54uUP6aQ03PmMO87orgi8qYrPdX+FrFExu8zquCz9qWUn7glJsbXFdbsPOEt+C2Dp0jd3e+wb3cwZSu4BpGGs+E8pzj5KeqJU5wIB8LB0nAryqVFTAWFKAtNMXMAhAALg5gVTBhRCS9DW7gQBYQgg2AaZ1PxI5Qbl9zUOExp2ISxKTQkHE/eGYEDQ4qCWr5X3CryVWedy9B38v8iv8y7lCLWlciNRZAVjYkCRsYsh4UlLSqKEh6MEwOJK1PSfq0hI4TwEvMzX4LsEJEZGvuqn6eGFXuGQETA48F79rOfVf3oRz+uh8izQDjtqxrHUuUHfngQhOyHp4Eg7ZALr4t7u5pzxzAZh3gs7EsC6FT47RvbPGtgD9hLcUUBIsbowVgQ/8cj5/8pNrtZ4sY5uOuhIqwiPCKf3x4W6jgII/rStnlEZWvCqmgV9CAg3Ttj7mA7eJz5A7In5KMRFMZXLR/EzG4vYFgiNYBcZIIZoMDBNU89xhV0R2hvGPEI+NacQCoyJ4yfabi6MGYRLs6KUGGeXOeOEBQhTPiEqJk2RUEeLU9phIanSpX2hMRFwZF0cnE1WERsMFqN8TTygPK6GLffDKmMOE0DDmMoRm1e6C8lFz9yniPKhiJPeKbYyTuCy/Byx5jNhdKU0pFQyLuEir7VjuJh3kmVNVFVDNVoFJ7FENEG/efigP2cpi0xDllPfFMfwP5AG60ruYDXm3ASIBqA4RgwrkQ4cm6OYxrKOlisL+MIMnDCSRNn/iY3SD1SLCzoHToxa8GjdDiLotnpui5DdhhPfbq/IAQ797NEWYwZR3pvvfN5+zvcoTrTGc9Yn1MGubjyj1He/jjE+U8WEb2kDL//A++vr8FpU8ybfaGTZMqsvsZMqqrqwpZwOFSkbajZMe1wHIVxmOGRZzYHuvgrOUxUhRQiNLjtZg30Fx2JMGyKkKjLKWBm+WOg8ynk9Fnmh5fRxxhR23hmV5up3tc0/Nlj8mHxZ8YARh08GT8gUzFcMzw4R3hO1Gtp9sXAhDekKYH0NHoWfsnADZr58kN4GKXgagzjJGj25dsgAoQmmy3dlNzWIaDGPad9lUTTwWP8Sv1T6vxQvChwfoc2DyFc6V0hqEPI8C0iFcCLx1Pddu9WvIOJY3Tt1YgzuOrQoBrPm5b/yHEmIHDdxzVFNhjBKxQ1V4zw6kZunI0o7yS8jzwXjANpeId1JJjFZdsjh7p2r1MqhdJ2AQGNF5KnqAscUvsvLRpDqLM30wvLfU94RKBjDVgaGSQov/aUPS3PkhV5Cugb26zta9Mc4mopY7bfw5jTtHLrZ54Cb+k4CZOUroB5w626cMBjRVANwdwcRTCEcJWG+VmvTbm7OGfNKVGRJ4VmoCGiW9BQxq7UgBjtpYpN2gdFhoeDcphCej+e9ggsPOVyatCtPpyGJ5Jnm4LEe0YgBF1hhZ5FPQaMk5JOAaU49dHydMyMHiJXUus1JYqgFZUi0/fR0ohEinDZKFbYtQ54IWOGPniTw1Pk/ajo69/t+OnnLWg/3gXgTq4vBVoNBoqD/F9CQ9+dtEPnAo4VFEvzrWOuPPZoXbNQJEOIdWMUsV+MCV1kcPV/Ywr7pTlf5hP7Imfft73D2M6w1aw5wbMOl3EDgW/thfAozNqf7xZBs7vGM7Ps8Mb9qnveq1t2mGf+M387kWiFfzmH6b3S6ZjQK7IsutYXckluSo1FzfOszan6ysHZLAX12tod047aEcEzs4u+VVWtT0QuZkrr0rRIjgcRFoyGYWTAu0ToREQZhw2ZfSh6Lgd/3lmE/DGvnJ479rb30lBw8iodDJ9hZGnyAcow508ajZvWcyD/UnzVH0p1QQZLBgcg4oGBcwicMbhOo0TRdrpYerMDOZr8nnNlUfQ5WsH1oaqOrFsYHMsmazVFz6EWqkQIgcAmROEM/x/FNDCNsHQjABBHKJGbSbES8iQUmRKbW7jJQmLeLLwUPkKNBfRjrH5Y2jEXzJ6lgYJHCWwyZEKeRbRQrA/Gx8pAKJSfJqdoqgM1tBHiufAynjNWEYddpUq4io3GI0JAbVY9ZmBAEOAFTuEpQvvqHJEXvuCAS7irqt5EhMKhoiC5Y17Ge0M8rxmKHGPi1YZPwtXQ1SH2a1pYh9WXcBsEIq6pOuiA7bFHnWNsz0VIvGf2DOF9nuiFJk6HxjbLGohqiIgA37d5LZwvoaPOtJCipgd0ln5908TlrAVdhvaFvpx/hDmKD6XKk/u0rRVgAW2LfJh1juvwXVSibRsL7ysDRwrWm7DMwk4pkZuDXvNIdBWws4d4kRiBKDO8IRQjDJ9HtwvwBPmoIi4wvMgfRaetRTP9JG0Hw6Q0hgdUf6JZROBQqvyN14gwilBrNI9CzLCnQIvxYuyh3KC3DFz4kTNMScND0ADvgqjk6Yo3CmAaGu17iq8UE0JgVFNXYCsVBihUlFTvi57YPSSrf+fYz7w3eIQw3wPJev2RyAA8baiOw9C58Bx/tBfg2PwZtHkI8JOuAn32DKWBQMyzS3lwxqwpZfIQqSE9h9c+5OFHV8MgMc95ItTx/NtT0qdi/tYpNWgyZBC2c+WRvjEtgmb39bcI2WEenK/Dt/aPsP1mVAUZCc3KuXaG4M2AHtBVCGeKvnJwxqvGY0ymEfUyK4xtR7QP/YAc5XcffY4xdfFXkRKM2uhEgDPHseXsU8AiipLMi2anV6XNOuf4bir5I9qTciOiaB45fZ45dTkT8TD6G32BnCq6Co1OK/wrkMjTHnwoVZaNqU2ebSq4sXZ0C2vIKOnfdBd0PIVI1Yr/ExnA2dHnfGrDzUwK7qxIDos2gYjgEcoEJRSCeFCEHFAglhGeN+s81uE7hxvhQjAJegRMCjuhwt99Bx1RaCpyFGJCiQ1EWJC7MQUDXw2u+lUawijjDOGWN4YVa0yIsHAMh90exQCjSFrMlRWRAB93GDdxQGBi/eq7BmtWvA2NbWy7aVGfZu5yW1tte2tsn/E+/FGwCdHCvVkTx+Yiju2bYEtg1y8LJ6BkORsYU1+15bF9rcv7UkUYJcO7Sali2OJhnTLvmQIEl20FhsbggnWXAXWIPlFkFZyioPd5Kof6ZkUWuSQMru8eW+00PZeEBMIAIyohAZ1OFb8oPuP/4po57TCmUnL9f1vxm6Exe55W9/c3fBFAGSLGKsxt5yJnDF3vUOwYGCj/DCzWh/IV10y0ftdC1nlvhLEJm++rmTDrWMkjIg4YMZwJQhvDx5QwNc0eGttkskOO5XBoMGvyHG2nACi0R9DHoxkyc2tKoG34I8eK8E88pO0qTdM9uK8vV8c4xjFH97UmKGsdBvyhVwzdDHM5zp8+/iq6hdFR2GsULEw7JrehZ8KSc/oag7up5Q/yuX01j5w+ZvzNd8MwjV4y4uam7FAuedhTeVXYsWgXPIVBV9RW83pI68V4wcjK8C01JrdeAYcCfsthKmKMUTz3LKbzXqqCG1Uzc+/Hmmcxd9q3PBusiGLex1o5psLVFvG7SVDCO8G7TohDCBAA4chtIY6TdLiARhBBxIZgzhtVYDsxQDAhRFCoMJMpLeHbgjHnmOGKgCD3iPLK+8trSZhlid77RntXRz3aUbOnHJZwhhuGt7Y8s3noqvbjnljpLDkelezBT/Ci8TFAUAjiapgJmi1NjMDAOsgOI4ZbXt0ADFCmplQ4OcFEuDDGUhCl1okUWUea1rc863TWpCJRdF3rGtGFUcgXP6NHiPKRBpoL8/Cq3D7GvLdUBVeoBzc9ptZrqR0zg/JuwcAkGFi3oznJpEojW4OBsj+3ZimTiQgljhDYtOjSJs511h06tTC8ibjbeWOedbfsPEzt+BlvxVbZikls3FZcqoLL6k3BxdAL5GOgHI18XJU3CwYKBgoGNgkD8vDlugnfElYcRb82aQ5LGWthhEtBc+lkBRhY5d5eZd8rQPVmd1kWa8z6LVXBHTOw8m7BQMFAwUDBQMHAtmNAnplCWoqpCCGW3z/lvdjbjr8yv+3AQBHdt2MdZ5rFShd/pZ3PhK7yUR4GioKbh6ed/VY5/zt7/cvsCwYKBhaKAblQqkTL81WlVzGzAgUDBQM7AwNFxDpwnQsidsaGX9Isi4K7JESXbg68q8KdFQUmxkDhChMjtDS3lhjY7n2uaJWK4QrSnfa0p13LFSiDKhgoGCgYKBgoGNgEDGypgrvdgtAmbKwyxoKBgoGCgYKBgoGCgZEYKOLLSISV1wsGCga2BQO7dlXVHhM5wrZUwd2WpS7zKBjYIAwUwWyDFqsMdf0wUA7Q+q3JhoxoYOvMvrNm/3JDMFeGWTBQMLClGCgK7pYu7PTTKoxuepwuuMV5lmyebxc8rSmaX870ltPLFPiYvY2dMMfZsVO+LBjYGRgodGA161zwvhq8r3evZVccsD5FwV3vfTrd6MqOnw6Xk7RUFmQSNJZGCgYKBgoGCgYKBgoGCgYKBgoGEgyshYK78aL+pBOYtLGy2QsGCgYWhYFyVBeF2dJuwUDBQMFAwUDBQMHAmmJgE8SftVBw13T9NmtYU2Zmb9bMN3e0i6QQi2x7czFeRr52GCgbde2WpDGgskLrvkJlfAUDBQMFAwUDTQwUBbfsiYKBTcdAkUA3fQVXN/6ydybFPXSCiYpATjq20ljBQMFAwUDBQMHATsFAUXB3ykpv0jyL0L1Jq1XGWjBQMFAwsF4YWAMeMjyE4TfWC6lLGE1ByRKQvMwuVrSgK+p2NGY3ZZyjJ7YeH2ytglv2zXpssDKKnY2Bcg539vqX2RcMFAxsBgYKrV6HdZp1FWb9bh3mXMZQMLAYDGytgrsYdK1Xq4WkrcF6lEVYg0UoQygYKBgoGCgYKBjYFAwUwWFTVqqMc3MxsAMU3EJINnd7lpEXDPRhoJztsj8KBgoGCgbmxUChpPNicHXfl7VbHe5Lz+uNgR2g4K73AgyPLoN8Zbwy3E95Y9EYKMu0aAz3tF+QvzjkF9wuDrfztlzWZl4Mlu8LBgoGCgYKBjYQA9un4BaGvoHbsAx5eRjYlAOyKeNc3srN2lPB5KyY2/zvytpv/hpu9Ay2eANu8dQ2esuVwRcMBAb+H8B5P2n5tB8CAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "ec1d8b40",
   "metadata": {
    "papermill": {
     "duration": 0.028276,
     "end_time": "2024-05-21T10:05:32.014739",
     "exception": false,
     "start_time": "2024-05-21T10:05:31.986463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# An implementation od the GELU activation function\n",
    "\n",
    "![GELU activation function.png](attachment:251c4c3d-22ee-45d0-81c6-7029e525dbac.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91df9084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.074820Z",
     "iopub.status.busy": "2024-05-21T10:05:32.074336Z",
     "iopub.status.idle": "2024-05-21T10:05:32.080339Z",
     "shell.execute_reply": "2024-05-21T10:05:32.079309Z"
    },
    "papermill": {
     "duration": 0.038839,
     "end_time": "2024-05-21T10:05:32.082357",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.043518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba967032",
   "metadata": {
    "papermill": {
     "duration": 0.027923,
     "end_time": "2024-05-21T10:05:32.138840",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.110917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A feed forward nural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1bb3904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.239601Z",
     "iopub.status.busy": "2024-05-21T10:05:32.238707Z",
     "iopub.status.idle": "2024-05-21T10:05:32.244970Z",
     "shell.execute_reply": "2024-05-21T10:05:32.244131Z"
    },
    "papermill": {
     "duration": 0.079823,
     "end_time": "2024-05-21T10:05:32.246884",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.167061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']),\n",
    "            nn.Dropout(cfg['drop_rate'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421c6ab",
   "metadata": {
    "papermill": {
     "duration": 0.028898,
     "end_time": "2024-05-21T10:05:32.304128",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.275230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# compute gradients in the models backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dfdfd01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.362238Z",
     "iopub.status.busy": "2024-05-21T10:05:32.361851Z",
     "iopub.status.idle": "2024-05-21T10:05:32.367663Z",
     "shell.execute_reply": "2024-05-21T10:05:32.366800Z"
    },
    "papermill": {
     "duration": 0.037198,
     "end_time": "2024-05-21T10:05:32.369634",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.332436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([0.])\n",
    "    \n",
    "    # calculate loss based on how close the target and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # print the mean absolute gradient of the weights\n",
    "            print(f'{name} has gradient mean of {param.grad.abs().mean().item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d700cc3",
   "metadata": {
    "papermill": {
     "duration": 0.027954,
     "end_time": "2024-05-21T10:05:32.425544",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.397590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce383f",
   "metadata": {
    "papermill": {
     "duration": 0.028053,
     "end_time": "2024-05-21T10:05:32.481677",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.453624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Multi-head attention layer:\n",
    "\n",
    "\n",
    "[more](https://www.kaggle.com/code/golammostofas/details-attention-mechanism-for-llm#4.2-An-Efficent-Multi-head-attention-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f9e690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.539446Z",
     "iopub.status.busy": "2024-05-21T10:05:32.539051Z",
     "iopub.status.idle": "2024-05-21T10:05:32.552106Z",
     "shell.execute_reply": "2024-05-21T10:05:32.551177Z"
    },
    "papermill": {
     "duration": 0.044322,
     "end_time": "2024-05-21T10:05:32.554133",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.509811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, block_size, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0 # d_out must be divisible by n_heads\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(torch.ones(block_size, block_size), diagonal=1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        \n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        mask_unsqueezed = mask_bool.unsqueeze(0).unsqueeze(0)\n",
    "        attn_scores.masked_fill_(mask_unsqueezed, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        \n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514c3d3",
   "metadata": {
    "papermill": {
     "duration": 0.029135,
     "end_time": "2024-05-21T10:05:32.610889",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.581754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## the transformer block components of GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd71672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.671498Z",
     "iopub.status.busy": "2024-05-21T10:05:32.670859Z",
     "iopub.status.idle": "2024-05-21T10:05:32.679431Z",
     "shell.execute_reply": "2024-05-21T10:05:32.678394Z"
    },
    "papermill": {
     "duration": 0.041733,
     "end_time": "2024-05-21T10:05:32.681313",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.639580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            block_size=cfg['ctx_len'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias'],\n",
    "        )\n",
    "        \n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_resid = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac1d5d",
   "metadata": {
    "papermill": {
     "duration": 0.028778,
     "end_time": "2024-05-21T10:05:32.738496",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.709718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The GPT model architecture implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb63312c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.797385Z",
     "iopub.status.busy": "2024-05-21T10:05:32.796464Z",
     "iopub.status.idle": "2024-05-21T10:05:32.805604Z",
     "shell.execute_reply": "2024-05-21T10:05:32.804678Z"
    },
    "papermill": {
     "duration": 0.040697,
     "end_time": "2024-05-21T10:05:32.807483",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.766786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['ctx_len'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )                                                                                   #A\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])                                        #B\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        \n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc1a444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.865899Z",
     "iopub.status.busy": "2024-05-21T10:05:32.865112Z",
     "iopub.status.idle": "2024-05-21T10:05:32.869425Z",
     "shell.execute_reply": "2024-05-21T10:05:32.868520Z"
    },
    "papermill": {
     "duration": 0.036042,
     "end_time": "2024-05-21T10:05:32.871424",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.835382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34cbec92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:32.929894Z",
     "iopub.status.busy": "2024-05-21T10:05:32.929045Z",
     "iopub.status.idle": "2024-05-21T10:05:34.647586Z",
     "shell.execute_reply": "2024-05-21T10:05:34.646592Z"
    },
    "papermill": {
     "duration": 1.750143,
     "end_time": "2024-05-21T10:05:34.650065",
     "exception": false,
     "start_time": "2024-05-21T10:05:32.899922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e01ac8",
   "metadata": {
    "papermill": {
     "duration": 0.027907,
     "end_time": "2024-05-21T10:05:34.706415",
     "exception": false,
     "start_time": "2024-05-21T10:05:34.678508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Analysis Model Architecture and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddcdf832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:34.765136Z",
     "iopub.status.busy": "2024-05-21T10:05:34.764181Z",
     "iopub.status.idle": "2024-05-21T10:05:34.770785Z",
     "shell.execute_reply": "2024-05-21T10:05:34.769968Z"
    },
    "papermill": {
     "duration": 0.038077,
     "end_time": "2024-05-21T10:05:34.772854",
     "exception": false,
     "start_time": "2024-05-21T10:05:34.734777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 162,419,712\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d5cc6",
   "metadata": {
    "papermill": {
     "duration": 0.027511,
     "end_time": "2024-05-21T10:05:34.828129",
     "exception": false,
     "start_time": "2024-05-21T10:05:34.800618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Curious we spoke of ninitializing a 124 million parameter CPT model so why is the actial number of parameters 163 million, as shown in the preceding code output?\n",
    "\n",
    "\n",
    "The reason is a concept called weight tying that is used in the original GPT-2 architecture, which means that the original GPT - 2 architecture is reusing the token embedding layer as its output layer. \n",
    "To understand what this means, let's take a look at the shapes of the token embedding layer and linear output layer that we initialized on the model via the GPTModel earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e693f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:34.886552Z",
     "iopub.status.busy": "2024-05-21T10:05:34.885639Z",
     "iopub.status.idle": "2024-05-21T10:05:34.891018Z",
     "shell.execute_reply": "2024-05-21T10:05:34.890082Z"
    },
    "papermill": {
     "duration": 0.036922,
     "end_time": "2024-05-21T10:05:34.893063",
     "exception": false,
     "start_time": "2024-05-21T10:05:34.856141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape:  torch.Size([50257, 768])\n",
      "Out layer shape:  torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print('Token embedding layer shape: ', model.tok_emb.weight.shape)\n",
    "print('Out layer shape: ', model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510e309",
   "metadata": {
    "papermill": {
     "duration": 0.02906,
     "end_time": "2024-05-21T10:05:34.950481",
     "exception": false,
     "start_time": "2024-05-21T10:05:34.921421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see based on the print outputs, the weight tensors for both these layers have the same shape.\n",
    "\n",
    "\n",
    "The token embedding and output layers are vary large due to the number of rows for the 50,257 in the tokenizer's vocabulary. Let's remove the output layer parameter count from the total GPT-2 model count according to the weight typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b30b100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:35.011959Z",
     "iopub.status.busy": "2024-05-21T10:05:35.011181Z",
     "iopub.status.idle": "2024-05-21T10:05:35.016354Z",
     "shell.execute_reply": "2024-05-21T10:05:35.015459Z"
    },
    "papermill": {
     "duration": 0.039234,
     "end_time": "2024-05-21T10:05:35.018710",
     "exception": false,
     "start_time": "2024-05-21T10:05:34.979476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying:  123822336\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f'Number of trainable parameters considering weight tying: ', total_params_gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4d3c9",
   "metadata": {
    "papermill": {
     "duration": 0.02802,
     "end_time": "2024-05-21T10:05:35.075611",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.047591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see, the model is now only 124 million parameters large, matching the original size of the GPT-2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11a9bf",
   "metadata": {
    "papermill": {
     "duration": 0.027532,
     "end_time": "2024-05-21T10:05:35.131174",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.103642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compute the memory requirements of the 163 million parameters in our GPTModel object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0af3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:35.189537Z",
     "iopub.status.busy": "2024-05-21T10:05:35.188663Z",
     "iopub.status.idle": "2024-05-21T10:05:35.194014Z",
     "shell.execute_reply": "2024-05-21T10:05:35.193115Z"
    },
    "papermill": {
     "duration": 0.037056,
     "end_time": "2024-05-21T10:05:35.196021",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.158965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model:  619.58 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f'Total size of the model: {total_size_mb: .2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367febc",
   "metadata": {
    "papermill": {
     "duration": 0.028296,
     "end_time": "2024-05-21T10:05:35.252755",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.224459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implement the token generation process as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b582e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:35.312341Z",
     "iopub.status.busy": "2024-05-21T10:05:35.311954Z",
     "iopub.status.idle": "2024-05-21T10:05:35.318322Z",
     "shell.execute_reply": "2024-05-21T10:05:35.317423Z"
    },
    "papermill": {
     "duration": 0.038506,
     "end_time": "2024-05-21T10:05:35.320256",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.281750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    while max_new_tokens:\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        max_new_tokens -= 1\n",
    "    \n",
    "    return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fca3f8",
   "metadata": {
    "papermill": {
     "duration": 0.027913,
     "end_time": "2024-05-21T10:05:35.376621",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.348708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility functions for text to token ID conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e67b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:35.434290Z",
     "iopub.status.busy": "2024-05-21T10:05:35.433603Z",
     "iopub.status.idle": "2024-05-21T10:05:38.308390Z",
     "shell.execute_reply": "2024-05-21T10:05:38.307456Z"
    },
    "papermill": {
     "duration": 2.906007,
     "end_time": "2024-05-21T10:05:38.310506",
     "exception": false,
     "start_time": "2024-05-21T10:05:35.404499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youEvery feminists Sadfell plotanse socio pioneeringAdjust infants\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    " \n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    " \n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    " \n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"ctx_len\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb4a2c",
   "metadata": {
    "papermill": {
     "duration": 0.027938,
     "end_time": "2024-05-21T10:05:38.366946",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.339008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7db3b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:38.425391Z",
     "iopub.status.busy": "2024-05-21T10:05:38.424636Z",
     "iopub.status.idle": "2024-05-21T10:05:38.433405Z",
     "shell.execute_reply": "2024-05-21T10:05:38.432530Z"
    },
    "papermill": {
     "duration": 0.04005,
     "end_time": "2024-05-21T10:05:38.435214",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.395164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids(' really like chocolate', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7805d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:38.494280Z",
     "iopub.status.busy": "2024-05-21T10:05:38.493456Z",
     "iopub.status.idle": "2024-05-21T10:05:38.498835Z",
     "shell.execute_reply": "2024-05-21T10:05:38.497958Z"
    },
    "papermill": {
     "duration": 0.03701,
     "end_time": "2024-05-21T10:05:38.500809",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.463799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consider the two input examples, which which have already been mapped to token IDs\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "# Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,   588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86422fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:38.558642Z",
     "iopub.status.busy": "2024-05-21T10:05:38.558332Z",
     "iopub.status.idle": "2024-05-21T10:05:38.640805Z",
     "shell.execute_reply": "2024-05-21T10:05:38.639763Z"
    },
    "papermill": {
     "duration": 0.113694,
     "end_time": "2024-05-21T10:05:38.642992",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.529298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c152498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:38.703009Z",
     "iopub.status.busy": "2024-05-21T10:05:38.702359Z",
     "iopub.status.idle": "2024-05-21T10:05:38.708858Z",
     "shell.execute_reply": "2024-05-21T10:05:38.707737Z"
    },
    "papermill": {
     "duration": 0.038754,
     "end_time": "2024-05-21T10:05:38.710894",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.672140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[50153],\n",
      "         [36902],\n",
      "         [42826]],\n",
      "\n",
      "        [[ 9580],\n",
      "         [39797],\n",
      "         [ 6972]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50dc5f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:38.771993Z",
     "iopub.status.busy": "2024-05-21T10:05:38.771115Z",
     "iopub.status.idle": "2024-05-21T10:05:38.776194Z",
     "shell.execute_reply": "2024-05-21T10:05:38.775361Z"
    },
    "papermill": {
     "duration": 0.038063,
     "end_time": "2024-05-21T10:05:38.778706",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.740643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  PRESIDENTanonNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c989e",
   "metadata": {
    "papermill": {
     "duration": 0.028612,
     "end_time": "2024-05-21T10:05:38.836761",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.808149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When we decode these tokens, we find that these output tokens are quite different from the target tokens we want the model to generate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3638f9d",
   "metadata": {
    "papermill": {
     "duration": 0.031591,
     "end_time": "2024-05-21T10:05:38.897222",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.865631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# implement the text evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aaf98f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:38.957368Z",
     "iopub.status.busy": "2024-05-21T10:05:38.956620Z",
     "iopub.status.idle": "2024-05-21T10:05:38.971304Z",
     "shell.execute_reply": "2024-05-21T10:05:38.970210Z"
    },
    "papermill": {
     "duration": 0.046317,
     "end_time": "2024-05-21T10:05:38.973344",
     "exception": false,
     "start_time": "2024-05-21T10:05:38.927027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.0455e-05, 3.4465e-05, 9.4933e-06])\n",
      "Text 2: tensor([7.5311e-06, 5.2012e-05, 5.1790e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    " \n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075faa41",
   "metadata": {
    "papermill": {
     "duration": 0.029606,
     "end_time": "2024-05-21T10:05:39.033679",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.004073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b66edb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.104223Z",
     "iopub.status.busy": "2024-05-21T10:05:39.103751Z",
     "iopub.status.idle": "2024-05-21T10:05:39.112083Z",
     "shell.execute_reply": "2024-05-21T10:05:39.111005Z"
    },
    "papermill": {
     "duration": 0.049012,
     "end_time": "2024-05-21T10:05:39.114468",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.065456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5605, -10.2756, -11.5649, -11.7965,  -9.8640, -12.1709])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f36ef8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.182201Z",
     "iopub.status.busy": "2024-05-21T10:05:39.181455Z",
     "iopub.status.idle": "2024-05-21T10:05:39.188134Z",
     "shell.execute_reply": "2024-05-21T10:05:39.187199Z"
    },
    "papermill": {
     "duration": 0.039595,
     "end_time": "2024-05-21T10:05:39.190010",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.150415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8721)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1ce5917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.249703Z",
     "iopub.status.busy": "2024-05-21T10:05:39.249329Z",
     "iopub.status.idle": "2024-05-21T10:05:39.255215Z",
     "shell.execute_reply": "2024-05-21T10:05:39.254346Z"
    },
    "papermill": {
     "duration": 0.03788,
     "end_time": "2024-05-21T10:05:39.257179",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.219299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8721)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fee2a",
   "metadata": {
    "papermill": {
     "duration": 0.02897,
     "end_time": "2024-05-21T10:05:39.314798",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.285828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross entropy loss\n",
    "\n",
    "At its core, the cross entropy loss is a popular measure in machine learning and deep learning that measures the difference between two probability distributions--typically, the true distribution of labels (here, tokens in a dataset) and the predicted distribution from a model (for instance, the token probabilities generated by an LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecdb5a33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.374782Z",
     "iopub.status.busy": "2024-05-21T10:05:39.374422Z",
     "iopub.status.idle": "2024-05-21T10:05:39.379276Z",
     "shell.execute_reply": "2024-05-21T10:05:39.378395Z"
    },
    "papermill": {
     "duration": 0.037727,
     "end_time": "2024-05-21T10:05:39.381781",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.344054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f38238e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.441950Z",
     "iopub.status.busy": "2024-05-21T10:05:39.441596Z",
     "iopub.status.idle": "2024-05-21T10:05:39.447491Z",
     "shell.execute_reply": "2024-05-21T10:05:39.446461Z"
    },
    "papermill": {
     "duration": 0.038078,
     "end_time": "2024-05-21T10:05:39.449439",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.411361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92de616a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.510141Z",
     "iopub.status.busy": "2024-05-21T10:05:39.509523Z",
     "iopub.status.idle": "2024-05-21T10:05:39.521406Z",
     "shell.execute_reply": "2024-05-21T10:05:39.520354Z"
    },
    "papermill": {
     "duration": 0.04452,
     "end_time": "2024-05-21T10:05:39.523437",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.478917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8721)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a5d51",
   "metadata": {
    "papermill": {
     "duration": 0.029634,
     "end_time": "2024-05-21T10:05:39.583003",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.553369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perplexity\n",
    "Perplexity is a measure often used alongside cross entropy loss to evaluate the performance of models in tasks like language modeling. It can provide a more interpretable way to understand the uncertainty of a model in predicting the next token in a sequence.\n",
    "\n",
    "Perplexity can be calculated as perplexity = torch.exp(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875049a5",
   "metadata": {
    "papermill": {
     "duration": 0.028927,
     "end_time": "2024-05-21T10:05:39.641154",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.612227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2705911",
   "metadata": {
    "papermill": {
     "duration": 0.030102,
     "end_time": "2024-05-21T10:05:39.700898",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.670796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code loads the \"The Verdict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b34493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.764407Z",
     "iopub.status.busy": "2024-05-21T10:05:39.763408Z",
     "iopub.status.idle": "2024-05-21T10:05:39.774099Z",
     "shell.execute_reply": "2024-05-21T10:05:39.773145Z"
    },
    "papermill": {
     "duration": 0.044008,
     "end_time": "2024-05-21T10:05:39.776198",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.732190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/input/the-verdict/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c114e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.837141Z",
     "iopub.status.busy": "2024-05-21T10:05:39.836222Z",
     "iopub.status.idle": "2024-05-21T10:05:39.846303Z",
     "shell.execute_reply": "2024-05-21T10:05:39.845385Z"
    },
    "papermill": {
     "duration": 0.042381,
     "end_time": "2024-05-21T10:05:39.848114",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.805733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead83523",
   "metadata": {
    "papermill": {
     "duration": 0.028972,
     "end_time": "2024-05-21T10:05:39.906034",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.877062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# To implement the data splitting\n",
    "\n",
    "we first define a train_ratio to use 90% of the data for training and the remaining 10% as validation data for model evaluation during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bacc858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:39.966472Z",
     "iopub.status.busy": "2024-05-21T10:05:39.965734Z",
     "iopub.status.idle": "2024-05-21T10:05:39.970454Z",
     "shell.execute_reply": "2024-05-21T10:05:39.969563Z"
    },
    "papermill": {
     "duration": 0.037163,
     "end_time": "2024-05-21T10:05:39.972370",
     "exception": false,
     "start_time": "2024-05-21T10:05:39.935207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d49cc",
   "metadata": {
    "papermill": {
     "duration": 0.029199,
     "end_time": "2024-05-21T10:05:40.032509",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.003310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using the train_data and val_data subsets, we can now create the respective data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8f442fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:40.093407Z",
     "iopub.status.busy": "2024-05-21T10:05:40.092670Z",
     "iopub.status.idle": "2024-05-21T10:05:40.101954Z",
     "shell.execute_reply": "2024-05-21T10:05:40.101054Z"
    },
    "papermill": {
     "duration": 0.04213,
     "end_time": "2024-05-21T10:05:40.103790",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.061660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    " \n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    " \n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    " \n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    return dataloader  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93cf4420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:40.163693Z",
     "iopub.status.busy": "2024-05-21T10:05:40.163359Z",
     "iopub.status.idle": "2024-05-21T10:05:40.178097Z",
     "shell.execute_reply": "2024-05-21T10:05:40.177221Z"
    },
    "papermill": {
     "duration": 0.047021,
     "end_time": "2024-05-21T10:05:40.180148",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.133127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    " \n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    stride=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    stride=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16af3133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:40.239959Z",
     "iopub.status.busy": "2024-05-21T10:05:40.239288Z",
     "iopub.status.idle": "2024-05-21T10:05:40.247566Z",
     "shell.execute_reply": "2024-05-21T10:05:40.246565Z"
    },
    "papermill": {
     "duration": 0.040341,
     "end_time": "2024-05-21T10:05:40.249562",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.209221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    " \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baaeb61",
   "metadata": {
    "papermill": {
     "duration": 0.029466,
     "end_time": "2024-05-21T10:05:40.309282",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.279816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we implement a utility function to calculate the cross entropy loss of a given batch returned via the training and validation loaderwe implement a utility function to calculate the cross entropy loss of a given batch returned via the training and validation loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73b27063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:40.371198Z",
     "iopub.status.busy": "2024-05-21T10:05:40.370348Z",
     "iopub.status.idle": "2024-05-21T10:05:40.375875Z",
     "shell.execute_reply": "2024-05-21T10:05:40.374970Z"
    },
    "papermill": {
     "duration": 0.038338,
     "end_time": "2024-05-21T10:05:40.377705",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.339367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abaea0cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:40.439143Z",
     "iopub.status.busy": "2024-05-21T10:05:40.438426Z",
     "iopub.status.idle": "2024-05-21T10:05:40.444746Z",
     "shell.execute_reply": "2024-05-21T10:05:40.443862Z"
    },
    "papermill": {
     "duration": 0.038581,
     "end_time": "2024-05-21T10:05:40.446614",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.408033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0def126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:40.506269Z",
     "iopub.status.busy": "2024-05-21T10:05:40.505932Z",
     "iopub.status.idle": "2024-05-21T10:05:41.778583Z",
     "shell.execute_reply": "2024-05-21T10:05:41.777482Z"
    },
    "papermill": {
     "duration": 1.304803,
     "end_time": "2024-05-21T10:05:41.780651",
     "exception": false,
     "start_time": "2024-05-21T10:05:40.475848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.998696539137098\n",
      "Validation loss: 10.980057716369629\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606fe929",
   "metadata": {
    "papermill": {
     "duration": 0.029003,
     "end_time": "2024-05-21T10:05:41.839299",
     "exception": false,
     "start_time": "2024-05-21T10:05:41.810296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e24ff4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:41.900841Z",
     "iopub.status.busy": "2024-05-21T10:05:41.900090Z",
     "iopub.status.idle": "2024-05-21T10:05:41.908569Z",
     "shell.execute_reply": "2024-05-21T10:05:41.907593Z"
    },
    "papermill": {
     "duration": 0.041746,
     "end_time": "2024-05-21T10:05:41.910768",
     "exception": false,
     "start_time": "2024-05-21T10:05:41.869022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    " \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    " \n",
    "        generate_and_print_sample(\n",
    "            model, train_loader.dataset.tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b3910be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:41.972403Z",
     "iopub.status.busy": "2024-05-21T10:05:41.971602Z",
     "iopub.status.idle": "2024-05-21T10:05:41.977419Z",
     "shell.execute_reply": "2024-05-21T10:05:41.976464Z"
    },
    "papermill": {
     "duration": 0.03881,
     "end_time": "2024-05-21T10:05:41.979362",
     "exception": false,
     "start_time": "2024-05-21T10:05:41.940552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78a5b6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:42.042280Z",
     "iopub.status.busy": "2024-05-21T10:05:42.041893Z",
     "iopub.status.idle": "2024-05-21T10:05:42.048124Z",
     "shell.execute_reply": "2024-05-21T10:05:42.047287Z"
    },
    "papermill": {
     "duration": 0.039376,
     "end_time": "2024-05-21T10:05:42.050085",
     "exception": false,
     "start_time": "2024-05-21T10:05:42.010709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab17d5",
   "metadata": {
    "papermill": {
     "duration": 0.02953,
     "end_time": "2024-05-21T10:05:42.108637",
     "exception": false,
     "start_time": "2024-05-21T10:05:42.079107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AdamW\n",
    "Adam optimizers are a popular choice for training deep neural networks. However, in our training loop, we opt for the AdamW optimizer. AdamW is a variant of Adam that improves the weight decay approach, which aims to minimize model complexity and prevent overfitting by penalizing larger weights. This adjustment allows AdamW to achieve more effective regularization and better generalization and is thus frequently used in the training of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fffcc23f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T10:05:42.169637Z",
     "iopub.status.busy": "2024-05-21T10:05:42.169187Z",
     "iopub.status.idle": "2024-05-21T10:07:12.008233Z",
     "shell.execute_reply": "2024-05-21T10:07:12.007139Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 89.872178,
     "end_time": "2024-05-21T10:07:12.010304",
     "exception": false,
     "start_time": "2024-05-21T10:05:42.138126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.074, Val loss 9.942\n",
      "Ep 1 (Step 000005): Train loss 8.163, Val loss 8.342\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.559, Val loss 7.052\n",
      "Ep 2 (Step 000015): Train loss 5.935, Val loss 6.606\n",
      "Every effort moves you, the,, and,,,,,,,,,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.877, Val loss 6.489\n",
      "Ep 3 (Step 000025): Train loss 5.479, Val loss 6.480\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.065, Val loss 6.504\n",
      "Ep 4 (Step 000035): Train loss 5.426, Val loss 6.488\n",
      "Every effort moves you, and he had the a, and the a, and the of the a, and he had the of the of the of the of the a of the of the of the of the of the of the of the of the of the of the\n",
      "Ep 5 (Step 000040): Train loss 5.187, Val loss 6.553\n",
      "Every effort moves you the a to the a \" it--I to the \" it--I it-- it-- \" it--I                           \n",
      "Ep 6 (Step 000045): Train loss 5.161, Val loss 6.421\n",
      "Ep 6 (Step 000050): Train loss 3.919, Val loss 6.350\n",
      "Every effort moves you, and, and in the picture--as, and, and, and I had been, I had been the, and, and, and I had been the picture, as, and, as, and, and \", and I had been\n",
      "Ep 7 (Step 000055): Train loss 4.646, Val loss 6.267\n",
      "Ep 7 (Step 000060): Train loss 3.295, Val loss 6.167\n",
      "Every effort moves you know to have to see that he had been--I had been.                      \"I me. I was a little the donkey, and I was\n",
      "Ep 8 (Step 000065): Train loss 3.277, Val loss 6.158\n",
      "Ep 8 (Step 000070): Train loss 2.452, Val loss 6.222\n",
      "Every effort moves you in the fact of that I felt of the fact that he had the last word.           \"Oh, and I had a little the donkey--and it the donkey, and the room, I had\n",
      "Ep 9 (Step 000075): Train loss 2.592, Val loss 6.144\n",
      "Ep 9 (Step 000080): Train loss 2.207, Val loss 6.233\n",
      "Every effort moves you know,\" was not that my dear--I felt nervous and I felt in a and in the picture to me to me.           \"Oh, I had the donkey, and it.   \n",
      "Ep 10 (Step 000085): Train loss 1.454, Val loss 6.223\n",
      "Every effort moves you know; and my surprise, one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"                    \n",
      "Ep 11 (Step 000090): Train loss 1.556, Val loss 6.239\n",
      "Ep 11 (Step 000095): Train loss 1.006, Val loss 6.265\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.                                    \n",
      "Ep 12 (Step 000100): Train loss 0.821, Val loss 6.336\n",
      "Ep 12 (Step 000105): Train loss 0.522, Val loss 6.411\n",
      "Every effort moves you?\"     I glanced after him, and uncertain.  \"Once, when I looked up, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 13 (Step 000110): Train loss 0.390, Val loss 6.442\n",
      "Ep 13 (Step 000115): Train loss 0.412, Val loss 6.573\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 14 (Step 000120): Train loss 0.306, Val loss 6.629\n",
      "Ep 14 (Step 000125): Train loss 0.230, Val loss 6.614\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 15 (Step 000130): Train loss 0.199, Val loss 6.696\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 16 (Step 000135): Train loss 0.190, Val loss 6.766\n",
      "Ep 16 (Step 000140): Train loss 0.136, Val loss 6.862\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 17 (Step 000145): Train loss 0.171, Val loss 6.914\n",
      "Ep 17 (Step 000150): Train loss 0.132, Val loss 6.878\n",
      "Every effort moves you?\" \"I turned back his pictures? I laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, instinctively embarrassed by my unexpected discovery; and as I turned, my eye fell on a small picture\n",
      "Ep 18 (Step 000155): Train loss 0.114, Val loss 6.985\n",
      "Ep 18 (Step 000160): Train loss 0.109, Val loss 7.044\n",
      "Every effort moves you?\" \"Oh, pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\" \"I looked at the donkey again. I saw that, when Stroud laid in the first\n",
      "Ep 19 (Step 000165): Train loss 0.090, Val loss 7.034\n",
      "Ep 19 (Step 000170): Train loss 0.076, Val loss 7.019\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n",
      "Ep 20 (Step 000175): Train loss 0.064, Val loss 7.069\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 21 (Step 000180): Train loss 0.039, Val loss 7.103\n",
      "Ep 21 (Step 000185): Train loss 0.040, Val loss 7.089\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 22 (Step 000190): Train loss 0.047, Val loss 7.106\n",
      "Ep 22 (Step 000195): Train loss 0.030, Val loss 7.204\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 23 (Step 000200): Train loss 0.030, Val loss 7.185\n",
      "Ep 23 (Step 000205): Train loss 0.041, Val loss 7.211\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 24 (Step 000210): Train loss 0.047, Val loss 7.224\n",
      "Ep 24 (Step 000215): Train loss 0.036, Val loss 7.177\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 25 (Step 000220): Train loss 0.018, Val loss 7.241\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 26 (Step 000225): Train loss 0.022, Val loss 7.307\n",
      "Ep 26 (Step 000230): Train loss 0.017, Val loss 7.318\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 27 (Step 000235): Train loss 0.016, Val loss 7.347\n",
      "Ep 27 (Step 000240): Train loss 0.014, Val loss 7.398\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 28 (Step 000245): Train loss 0.011, Val loss 7.369\n",
      "Ep 28 (Step 000250): Train loss 0.011, Val loss 7.395\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 29 (Step 000255): Train loss 0.013, Val loss 7.482\n",
      "Ep 29 (Step 000260): Train loss 0.029, Val loss 7.422\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 30 (Step 000265): Train loss 0.008, Val loss 7.380\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 31 (Step 000270): Train loss 0.018, Val loss 7.425\n",
      "Ep 31 (Step 000275): Train loss 0.009, Val loss 7.488\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 32 (Step 000280): Train loss 0.009, Val loss 7.484\n",
      "Ep 32 (Step 000285): Train loss 0.006, Val loss 7.493\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 33 (Step 000290): Train loss 0.006, Val loss 7.487\n",
      "Ep 33 (Step 000295): Train loss 0.005, Val loss 7.488\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 34 (Step 000300): Train loss 0.006, Val loss 7.525\n",
      "Ep 34 (Step 000305): Train loss 0.005, Val loss 7.534\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 35 (Step 000310): Train loss 0.004, Val loss 7.536\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 36 (Step 000315): Train loss 0.006, Val loss 7.558\n",
      "Ep 36 (Step 000320): Train loss 0.004, Val loss 7.538\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 37 (Step 000325): Train loss 0.005, Val loss 7.569\n",
      "Ep 37 (Step 000330): Train loss 0.009, Val loss 7.555\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 38 (Step 000335): Train loss 0.003, Val loss 7.571\n",
      "Ep 38 (Step 000340): Train loss 0.004, Val loss 7.580\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 39 (Step 000345): Train loss 0.003, Val loss 7.574\n",
      "Ep 39 (Step 000350): Train loss 0.003, Val loss 7.589\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 40 (Step 000355): Train loss 0.003, Val loss 7.601\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 41 (Step 000360): Train loss 0.003, Val loss 7.615\n",
      "Ep 41 (Step 000365): Train loss 0.003, Val loss 7.633\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 42 (Step 000370): Train loss 0.003, Val loss 7.652\n",
      "Ep 42 (Step 000375): Train loss 0.003, Val loss 7.662\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 43 (Step 000380): Train loss 0.003, Val loss 7.671\n",
      "Ep 43 (Step 000385): Train loss 0.003, Val loss 7.678\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 44 (Step 000390): Train loss 0.002, Val loss 7.682\n",
      "Ep 44 (Step 000395): Train loss 0.002, Val loss 7.693\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 45 (Step 000400): Train loss 0.002, Val loss 7.706\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 46 (Step 000405): Train loss 0.002, Val loss 7.714\n",
      "Ep 46 (Step 000410): Train loss 0.002, Val loss 7.697\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 47 (Step 000415): Train loss 0.002, Val loss 7.696\n",
      "Ep 47 (Step 000420): Train loss 0.002, Val loss 7.715\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 48 (Step 000425): Train loss 0.002, Val loss 7.734\n",
      "Ep 48 (Step 000430): Train loss 0.002, Val loss 7.739\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 49 (Step 000435): Train loss 0.002, Val loss 7.731\n",
      "Ep 49 (Step 000440): Train loss 0.002, Val loss 7.723\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 50 (Step 000445): Train loss 0.002, Val loss 7.726\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2cc4b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:12.092350Z",
     "iopub.status.busy": "2024-05-21T10:07:12.091854Z",
     "iopub.status.idle": "2024-05-21T10:07:12.863135Z",
     "shell.execute_reply": "2024-05-21T10:07:12.861834Z"
    },
    "papermill": {
     "duration": 0.816642,
     "end_time": "2024-05-21T10:07:12.867457",
     "exception": false,
     "start_time": "2024-05-21T10:07:12.050815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    " \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1173a97c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:12.974569Z",
     "iopub.status.busy": "2024-05-21T10:07:12.973708Z",
     "iopub.status.idle": "2024-05-21T10:07:14.052461Z",
     "shell.execute_reply": "2024-05-21T10:07:14.051515Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.122498,
     "end_time": "2024-05-21T10:07:14.054889",
     "exception": false,
     "start_time": "2024-05-21T10:07:12.932391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b097a15c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:14.136119Z",
     "iopub.status.busy": "2024-05-21T10:07:14.135808Z",
     "iopub.status.idle": "2024-05-21T10:07:20.036093Z",
     "shell.execute_reply": "2024-05-21T10:07:20.034754Z"
    },
    "papermill": {
     "duration": 5.942956,
     "end_time": "2024-05-21T10:07:20.038166",
     "exception": false,
     "start_time": "2024-05-21T10:07:14.095210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Who is Mrs. Gideon Thwing, and what is her reaction to Jack Gisburn's \"abdication\"?\n",
      "A slight shade of constraint crossed Mrs. Gisburn's open countenance. \"It's his ridiculous modesty, you know. He says they're not fit to have about; he's sent them all away except one--my portrait--and\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(f'Who is Mrs. Gideon Thwing, and what is her reaction to Jack Gisburn\\'s \"abdication\"?', tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"ctx_len\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ddd12",
   "metadata": {
    "papermill": {
     "duration": 0.040086,
     "end_time": "2024-05-21T10:07:20.119819",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.079733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e3d8aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:20.202512Z",
     "iopub.status.busy": "2024-05-21T10:07:20.202128Z",
     "iopub.status.idle": "2024-05-21T10:07:20.207497Z",
     "shell.execute_reply": "2024-05-21T10:07:20.206635Z"
    },
    "papermill": {
     "duration": 0.049505,
     "end_time": "2024-05-21T10:07:20.209501",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.159996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be16eb",
   "metadata": {
    "papermill": {
     "duration": 0.039766,
     "end_time": "2024-05-21T10:07:20.289470",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.249704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "assume the LLM is given the start context \"every effort moves you\" and generates the following next-token logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b930de32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:20.371573Z",
     "iopub.status.busy": "2024-05-21T10:07:20.370809Z",
     "iopub.status.idle": "2024-05-21T10:07:20.376452Z",
     "shell.execute_reply": "2024-05-21T10:07:20.375508Z"
    },
    "papermill": {
     "duration": 0.049324,
     "end_time": "2024-05-21T10:07:20.378459",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.329135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13179502",
   "metadata": {
    "papermill": {
     "duration": 0.039867,
     "end_time": "2024-05-21T10:07:20.458697",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.418830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As discussed in the previous chapter, Inside the generate_text_simple, we convert the logits into probabilities via the softmax function and obtain the token ID corresponding the generated token via the argmax function, which we can then map back into text via the inverse vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d26366bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:20.540393Z",
     "iopub.status.busy": "2024-05-21T10:07:20.539497Z",
     "iopub.status.idle": "2024-05-21T10:07:20.545735Z",
     "shell.execute_reply": "2024-05-21T10:07:20.544616Z"
    },
    "papermill": {
     "duration": 0.04935,
     "end_time": "2024-05-21T10:07:20.547750",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.498400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996375d2",
   "metadata": {
    "papermill": {
     "duration": 0.040268,
     "end_time": "2024-05-21T10:07:20.628640",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.588372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To implement a probabilistic sampling process, we can now replace the argmax with the multinomial function in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d402537c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:20.710483Z",
     "iopub.status.busy": "2024-05-21T10:07:20.710105Z",
     "iopub.status.idle": "2024-05-21T10:07:20.716770Z",
     "shell.execute_reply": "2024-05-21T10:07:20.715770Z"
    },
    "papermill": {
     "duration": 0.049846,
     "end_time": "2024-05-21T10:07:20.718628",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.668782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d69c5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:20.800206Z",
     "iopub.status.busy": "2024-05-21T10:07:20.799909Z",
     "iopub.status.idle": "2024-05-21T10:07:20.840071Z",
     "shell.execute_reply": "2024-05-21T10:07:20.839053Z"
    },
    "papermill": {
     "duration": 0.083586,
     "end_time": "2024-05-21T10:07:20.842326",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.758740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "324fe58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:20.925823Z",
     "iopub.status.busy": "2024-05-21T10:07:20.925466Z",
     "iopub.status.idle": "2024-05-21T10:07:20.930169Z",
     "shell.execute_reply": "2024-05-21T10:07:20.929296Z"
    },
    "papermill": {
     "duration": 0.048311,
     "end_time": "2024-05-21T10:07:20.932083",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.883772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b572b831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:21.014844Z",
     "iopub.status.busy": "2024-05-21T10:07:21.014484Z",
     "iopub.status.idle": "2024-05-21T10:07:21.369369Z",
     "shell.execute_reply": "2024-05-21T10:07:21.368506Z"
    },
    "papermill": {
     "duration": 0.398645,
     "end_time": "2024-05-21T10:07:21.371553",
     "exception": false,
     "start_time": "2024-05-21T10:07:20.972908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM5klEQVR4nO3deVxU1f8/8Newg2wimyAKiiYUO0q4oUWCGmqkGWooIt8scYFwjUUgwDQR/YRiKu5rRlqaJvIRcc0dMxEDREhBcSVA1jm/P/xxP44DyH7v4Pv5eMzjw5y5d+Y185l8zz333HNEjDEGQgghhAiSHN8BCCGEEFI/KtSEEEKIgFGhJoQQQgSMCjUhhBAiYFSoCSGEEAGjQk0IIYQIGBVqQgghRMCoUBNCCCECpsB3gPYmFotx7949aGhoQCQS8R2HEELIG4gxhn///RdGRkaQk2v4mPmNK9T37t2DiYkJ3zEIIYQQ5Ofno1u3bg1u88YVag0NDQAvPhxNTU2e0xBCCHkTFRcXw8TEhKtJDXnjCnVtd7empiYVakIIIbxqzClYGkxGCCGECBivhTotLQ0eHh4wMjKCSCTC/v37X7tPamoq7O3toaysDHNzc2zevLnNcxJCCCF84bVQl5aWwsbGBvHx8Y3a/vbt2xg1ahSGDRuGq1evYu7cuZg+fTp+//33Nk5KCCGE8IPXc9QjRozAiBEjGr19QkICzMzMsGLFCgCAhYUFTp06hZUrV8LNza2tYhJC2plYLEZlZSXfMQhpNkVFRcjLy7fKc8nUYLKzZ8/C1dVVos3NzQ1z586td5+KigpUVFRw94uLi9sqHiGkFVRWVuL27dsQi8V8RyGkRbS1tWFoaNjiOTtkqlAXFhbCwMBAos3AwADFxcV4/vw5VFVVpfaJiYlBeHh4e0UkhLQAYwwFBQWQl5eHiYnJayeCIESIGGMoKyvDgwcPAABdu3Zt0fPJVKFujkWLFiEwMJC7X3vtGiFEeKqrq1FWVgYjIyOoqanxHYeQZqs9cHzw4AH09fVb1A0uU4Xa0NAQ9+/fl2i7f/8+NDU16zyaBgBlZWUoKyu3RzxCGm+JVgOPPWu/HAJTU1MDAFBSUuI5CSEtV/tjs6qqqkWFWqb6lZydnZGSkiLRlpycDGdnZ54SEULaAs3DTzqC1voe81qoS0pKcPXqVVy9ehXAi8uvrl69iry8PAAvuq29vb257WfMmIGcnBzMnz8fN2/exJo1a7B3714EBATwEZ8QQghpc7wW6osXL8LOzg52dnYAgMDAQNjZ2SE0NBQAUFBQwBVtADAzM8OhQ4eQnJwMGxsbrFixAhs2bKBLswghhHRYvJ6jHjp0KBhj9T5e16xjQ4cOxZUrV9owFSFEaEwXHmrX18tdOqrR276uezMsLAxLlixpYSJhMTU1xdy5cxu8NFboZs+ejdOnT+P69euwsLDgenaFSKYGkxFCiNAUFBRwf+/ZswehoaHIzMzk2tTV1fmI1WSMMdTU1EBBof3KQmVlJa8DB6dNm4Y//vgD165d4y1DY8jUYDJCCBEaQ0ND7qalpQWRSCTRtnv3blhYWEBFRQV9+/bFmjVruH1zc3MhEomwd+9eDB48GKqqqujXrx9u3bqFCxcuwNHREerq6hgxYgSKioq4/aZOnYqxY8ciPDwcenp60NTUxIwZMyRmcxOLxYiJiYGZmRlUVVVhY2ODffv2cY+npqZCJBLh8OHDcHBwgLKyMk6dOoXs7GyMGTMGBgYGUFdXR79+/XDs2DFuv6FDh+LOnTsICAiASCTiehSWLFkCW1tbic8mLi4OpqamUrmjoqJgZGSEt956C8CLZYc/+eQTaGtrQ0dHB2PGjEFubm5r/N9Tr9WrV2PmzJno2bNnm75Oa6BCTQghbWTHjh0IDQ1FVFQUMjIyEB0djZCQEGzZskViu7CwMAQHB+Py5ctQUFDAxIkTMX/+fKxatQonT55EVlYWN3anVkpKCjIyMpCamopdu3YhKSlJYnKnmJgYbN26FQkJCfjrr78QEBCAyZMn48SJExLPs3DhQixduhQZGRmwtrZGSUkJRo4ciZSUFFy5cgXu7u7w8PDgxgslJSWhW7duiIiIQEFBgUSPQmOkpKQgMzMTycnJOHjwIKqqquDm5gYNDQ2cPHkSp0+fhrq6Otzd3RucRlZdXb3B24wZM5qUS8io65sQQtpIWFgYVqxYAU9PTwAvBsTeuHED69atw5QpU7jtgoKCuEGxc+bMgZeXF1JSUjBw4EAAgK+vr9SYHSUlJSQmJkJNTQ1vv/02IiIiMG/ePERGRqKqqgrR0dE4duwYd/lqz549cerUKaxbtw4uLi7c80REROCDDz7g7uvo6MDGxoa7HxkZiZ9//hm//PIL/P39oaOjA3l5eWhoaMDQ0LDJn0mnTp2wYcMGrst7+/btEIvF2LBhA3d0vmnTJmhrayM1NRXDhw+v83led05ZU1OzydmEigo1IYS0gdLSUmRnZ8PX1xd+fn5ce3V1NbS0JCe8sba25v6unSbZyspKoq12OspaNjY2ErO3OTs7o6SkBPn5+SgpKUFZWZlEAQZenBOuvcqmlqOjo8T9kpISLFmyBIcOHUJBQQGqq6vx/PlziStwWsLKykrivHR6ejqysrKgoaEhsV15eTmys7PrfR5zc/NWySMLqFATQkgbKCkpAQCsX78eTk5OEo+9OkuVoqIi93ftUeWrbU1ZpKT2tQ8dOgRjY2OJx16dqbFTp04S94OCgpCcnIzvvvsO5ubmUFVVxbhx4167mpmcnJzUVTxVVVVS2736eiUlJXBwcMCOHTukttXT06v39V43SG/y5MlISEhocBtZQYWaEELagIGBAYyMjJCTk4NJkya1+vOnp6dLLEZ07tw5qKurw8TEBDo6OlBWVkZeXp5EN3djnD59GlOnTsVHH30E4EUhfXVgl5KSEjfday09PT0UFhaCMcb92GjMJU/29vbYs2cP9PX1m9RdTV3fhBBCWiw8PByzZ8+GlpYW3N3dUVFRgYsXL+LJkycSiwU1R2VlJXx9fREcHIzc3FyEhYXB398fcnJy0NDQQFBQEAICAiAWizFo0CA8e/YMp0+fhqampsT58Vf17t0bSUlJ8PDwgEgkQkhIiNTRvKmpKdLS0vDpp59CWVkZurq6GDp0KIqKirBs2TKMGzcOR44cweHDh19bMCdNmoTly5djzJgxiIiIQLdu3XDnzh0kJSVh/vz56NatW537tbTrOysrCyUlJSgsLMTz58+5wm9paSm4ueZp1DchhLSR6dOnY8OGDdi0aROsrKzg4uKCzZs3w8zMrMXP/f7776N3794YMmQIJkyYgNGjR0tMrBIZGYmQkBDExMTAwsIC7u7uOHTo0GtfOzY2Fp07d8aAAQPg4eEBNzc32NvbS2wTERGB3Nxc9OrVi+uetrCwwJo1axAfHw8bGxucP38eQUFBr30fampqSEtLQ/fu3eHp6QkLCwv4+vqivLy8TY+Kp0+fDjs7O6xbtw63bt3iZsm8d+9em71mc4lYQ1ODdUDFxcXQ0tLCs2fPOlTXCJExtHpWncrLy3H79m2YmZlBRUWF7ziCNXXqVDx9+hT79+/nOwppQEPf56bUIjqiJoQQQgSMCjUhhBAiYDSYjBBCZExdCxaRjouOqAkhhBABo0JNCCGECBgVakIIIUTAqFATQgghAkaFmhBCCBEwKtSEEEKIgFGhJoSQFhCJRA3eXp7Ws6MwNTVFXFwc3zFaJC8vD6NGjYKamhr09fUxb948VFdXN7hPVFQUBgwYADU1NWhra7dPUNB11IQQWdDQlKtt8nqNn8a1oKCA+3vPnj0IDQ1FZmYm1/a65RiFgjGGmpoaKCi0X1morKzkZQGMmpoajBo1CoaGhjhz5gwKCgrg7e0NRUVFREdH17tfZWUlxo8fD2dnZ2zcuLHd8tIRNSGEtIChoSF309LSgkgkkmjbvXs3LCwsoKKigr59+2LNmjXcvrm5uRCJRNi7dy8GDx4MVVVV9OvXD7du3cKFCxfg6OgIdXV1jBgxAkVFRdx+U6dOxdixYxEeHg49PT1oampixowZEmtGi8VixMTEwMzMDKqqqrCxscG+ffu4x1NTUyESiXD48GE4ODhAWVkZp06dQnZ2NsaMGQMDAwOoq6ujX79+OHbsGLff0KFDcefOHQQEBHC9BgCwZMkS2NraSnw2cXFxMDU1lcodFRUFIyMjvPXWWwCA/Px8fPLJJ9DW1oaOjg7GjBkjtbRmazp69Chu3LiB7du3w9bWFiNGjEBkZCTi4+MbXHc7PDwcAQEBsLKyarNsdaFCTQghbWTHjh0IDQ1FVFQUMjIyEB0djZCQEGzZskViu7CwMAQHB+Py5ctQUFDAxIkTMX/+fKxatQonT55EVlYWQkNDJfZJSUlBRkYGUlNTsWvXLiQlJSE8PJx7PCYmBlu3bkVCQgL++usvBAQEYPLkyThx4oTE8yxcuBBLly5FRkYGrK2tUVJSgpEjRyIlJQVXrlyBu7s7PDw8kJeXBwBISkpCt27dEBERgYKCAokehcZISUlBZmYmkpOTcfDgQVRVVcHNzQ0aGho4efIkTp8+DXV1dbi7uzdYNNXV1Ru8zZgxo959z549CysrKxgYGHBtbm5uKC4uxl9//dWk99MeqOubEELaSFhYGFasWAFPT08AgJmZGW7cuIF169ZJrAkdFBQENzc3AMCcOXPg5eWFlJQUDBw4EADg6+srNW2okpISEhMToaamhrfffhsRERGYN28eIiMjUVVVhejoaBw7dgzOzs4AgJ49e+LUqVNYt24dXFxcuOeJiIjABx98wN3X0dGBjY0Ndz8yMhI///wzfvnlF/j7+0NHRwfy8vLQ0NCAoaFhkz+TTp06YcOGDVyX9/bt2yEWi7Fhwwbu6HzTpk3Q1tZGamoqhg8fXufz1K4fXZ+GVqQqLCyUKNIAuPuFhYWNfSvthgo1IYS0gdLSUmRnZ8PX1xd+fn5ce3V1NbS0JM+5W1tbc3/XFoyXu1cNDAzw4MEDiX1sbGygpqbG3Xd2dkZJSQny8/NRUlKCsrIyiQIMvDjHamdnJ9Hm6Ogocb+kpARLlizBoUOHUFBQgOrqajx//pw7om4pKysrifPS6enpyMrKgoaGhsR25eXlyM7Orvd5zM3NWyWPLKBCTQghbaCkpAQAsH79ejg5OUk8Ji8vL3FfUVGR+7v2qPLVNrFY3OTXPnToEIyNjSUeU1ZWlrjfqVMniftBQUFITk7Gd999B3Nzc6iqqmLcuHENdkMDgJycHBhjEm1VVVVS2736eiUlJXBwcMCOHTukttXT06v39V43SG/y5MlISEio8zFDQ0OcP39eou3+/fvcY0JDhZoQQtqAgYEBjIyMkJOTg0mTJrX686enp+P58+dQVVUFAJw7dw7q6uowMTGBjo4OlJWVkZeXJ9HN3RinT5/G1KlT8dFHHwF4UUhfHdilpKSEmpoaiTY9PT0UFhaCMcb92Hhd9zQA2NvbY8+ePdDX12+wu/pVLen6dnZ2RlRUFB48eAB9fX0AQHJyMjQ1NWFpadnoDO2FCjUhhLSR8PBwzJ49G1paWnB3d0dFRQUuXryIJ0+eIDAwsEXPXVlZCV9fXwQHByM3NxdhYWHw9/eHnJwcNDQ0EBQUhICAAIjFYgwaNAjPnj3D6dOnoampKXF+/FW9e/dGUlISPDw8IBKJEBISInU0b2pqirS0NHz66adQVlaGrq4uhg4diqKiIixbtgzjxo3DkSNHcPjw4dcW30mTJmH58uUYM2YMIiIi0K1bN9y5cwdJSUmYP38+unXrVud+Len6Hj58OCwtLfHZZ59h2bJlKCwsRHBwMGbOnMn1OJw/fx7e3t5ISUnheiXy8vLw+PFj5OXloaamhvuxYG5u3qaX4fE+6js+Ph6mpqZQUVGBk5OTVHfEq+Li4vDWW29BVVUVJiYmCAgIQHl5eTulJYSQxps+fTo2bNiATZs2wcrKCi4uLti8eTPMzMxa/Nzvv/8+evfujSFDhmDChAkYPXq0xOQqkZGRCAkJQUxMDCwsLODu7o5Dhw699rVjY2PRuXNnDBgwAB4eHnBzc4O9vb3ENhEREcjNzUWvXr247mkLCwusWbMG8fHxsLGxwfnz5xEUFPTa96Gmpoa0tDR0794dnp6esLCwgK+vL8rLy5t0hN0U8vLyOHjwIOTl5eHs7IzJkyfD29sbERER3DZlZWXIzMyU6L4PDQ2FnZ0dwsLCUFJSAjs7O9jZ2eHixYttkrOWiL16UqEd7dmzB97e3khISICTkxPi4uLw448/IjMzk+uOeNnOnTsxbdo0JCYmYsCAAbh16xamTp2KTz/9FLGxsY16zeLiYmhpaeHZs2dt9iUg5LUamsCjCZNtdDTl5eW4ffs2zMzMoKKiwnccwZo6dSqePn2K/fv38x2FNKCh73NTahGvR9SxsbHw8/ODj48PLC0tkZCQADU1NSQmJta5/ZkzZzBw4EBMnDgRpqamGD58OLy8vF57FE4IIYTIKt4KdWVlJS5dugRXV9f/hZGTg6urK86ePVvnPgMGDMClS5e4wpyTk4PffvsNI0eObJfMhBBCSHvjbTDZw4cPUVNTU+dF5zdv3qxzn4kTJ+Lhw4cYNGgQGGOorq7GjBkzsHjx4npfp6KiAhUVFdz94uLi1nkDhBDCk1cnPyEdG++DyZoiNTUV0dHRWLNmDS5fvoykpCQcOnQIkZGR9e4TExMDLS0t7mZiYtKOiQkhhJCW4e2IWldXF/Ly8txF5rXu379f7wXnISEh+OyzzzB9+nQAL2a4KS0txf/93//h66+/hpyc9O+ORYsWSVwGUVxcTMWaEEKIzODtiFpJSQkODg5ISUnh2sRiMVJSUri5aV9VVlYmVYxrZ/ipb/C6srIyNDU1JW6EEEKIrOB1wpPAwEBMmTIFjo6O6N+/P+Li4lBaWgofHx8AgLe3N4yNjRETEwMA8PDwQGxsLOzs7ODk5ISsrCyEhITAw8NDako+QgghpCPgtVBPmDABRUVFCA0NRWFhIWxtbXHkyBFugFleXp7EEXRwcDBEIhGCg4Nx9+5d6OnpwcPDA1FRUXy9BUIIIaRN8TrhCR9owhMiCDThSZ1owhPSkXSICU8IIYQQ0jAq1IQQ0gIikajB28vzb3cUpqamiIuL4ztGi9T1/9Xu3bv5jlUnWj2LECJ4Vlus2vX1/pzyZ6O3LSgo4P7es2cPQkNDkZmZybW15apKrYkxhpqaGigotF9ZqKyshJKSUru93qs2bdoEd3d37r62tjZvWRpCR9SEENIChoaG3E1LSwsikUiibffu3bCwsICKigr69u2LNWvWcPvm5uZCJBJh7969GDx4MFRVVdGvXz/cunULFy5cgKOjI9TV1TFixAgUFRVx+02dOhVjx45FeHg49PT0oKmpiRkzZqCyspLbRiwWIyYmBmZmZlBVVYWNjQ327dvHPZ6amgqRSITDhw/DwcEBysrKOHXqFLKzszFmzBgYGBhAXV0d/fr1w7Fjx7j9hg4dijt37iAgIIA7EgWAJUuWwNbWVuKziYuLg6mpqVTuqKgoGBkZ4a233gIA5Ofn45NPPoG2tjZ0dHQwZswYqTWw24K2trbE/1dCHRdBhZoQQtrIjh07EBoaiqioKGRkZCA6OhohISHYsmWLxHZhYWEIDg7G5cuXoaCggIkTJ2L+/PlYtWoVTp48iaysLISGhkrsk5KSgoyMDKSmpmLXrl1ISkpCeHg493hMTAy2bt2KhIQE/PXXXwgICMDkyZNx4sQJiedZuHAhli5dioyMDFhbW6OkpAQjR45ESkoKrly5And3d3h4eCAvLw8AkJSUhG7duiEiIgIFBQUSPQqNkZKSgszMTCQnJ+PgwYOoqqqCm5sbNDQ0cPLkSZw+fRrq6upwd3eX+OHxKnV19QZvM2bMeG2WmTNnQldXF/3790diYmK983Hwjbq+CSGkjYSFhWHFihXw9PQEAJiZmeHGjRtYt24dpkyZwm0XFBQENzc3AMCcOXPg5eWFlJQUDBw4EADg6+srNb+3kpISEhMToaamhrfffhsRERGYN28eIiMjUVVVhejoaBw7doybQKpnz544deoU1q1bBxcXF+55IiIi8MEHH3D3dXR0YGNjw92PjIzEzz//jF9++QX+/v7Q0dGBvLw8NDQ06p1FsiGdOnXChg0buC7v7du3QywWY8OGDdzR+aZNm6CtrY3U1FQMHz68zue5evVqg6/zupHUEREReO+996CmpoajR4/iyy+/RElJCWbPnt3k99TWqFATQkgbKC0tRXZ2Nnx9feHn58e1V1dXQ0tL8vI8a2tr7u/aeSSsrKwk2h48eCCxj42NDdTU1Lj7zs7OKCkpQX5+PkpKSlBWViZRgIEX54Tt7Owk2hwdHSXul5SUYMmSJTh06BAKCgpQXV2N58+fc0fULWVlZSVxXjo9PR1ZWVnQ0NCQ2K68vBzZ2dn1Po+5uXmLcoSEhHB/29nZobS0FMuXL6dCTQghb4qSkhIAwPr16+Hk5CTx2KszKSoqKnJ/1x5VvtomFoub/NqHDh2CsbGxxGPKysoS9zt16iRxPygoCMnJyfjuu+9gbm4OVVVVjBs3rsFuaODFMsWvdh1XVVVJbffq65WUlMDBwQE7duyQ2lZPT6/e13vdIL3JkycjISGhwW1e5uTkhMjISFRUVEh9RnyjQk0IIW3AwMAARkZGyMnJwaRJk1r9+dPT0/H8+XOoqqoCAM6dOwd1dXWYmJhAR0cHysrKyMvLk+jmbozTp09j6tSp+OijjwC8KKSvDuxSUlJCTU2NRJuenh4KCwvBGON+bLyuexoA7O3tsWfPHujr6zdpEqqWdn3X9XydO3cWXJEGqFATQkibCQ8Px+zZs6GlpQV3d3dUVFTg4sWLePLkicSqfs1RWVkJX19fBAcHIzc3F2FhYfD394ecnBw0NDQQFBSEgIAAiMViDBo0CM+ePcPp06ehqakpcX78Vb1790ZSUhI8PDwgEokQEhIidTRvamqKtLQ0fPrpp1BWVoauri6GDh2KoqIiLFu2DOPGjcORI0dw+PDh1xbMSZMmYfny5RgzZgwiIiLQrVs33LlzB0lJSZg/fz66detW534t6fr+9ddfcf/+fbz77rtQUVFBcnIyoqOjERQU1OznbEs06psQQtrI9OnTsWHDBmzatAlWVlZwcXHB5s2bYWZm1uLnfv/999G7d28MGTIEEyZMwOjRoyUmV4mMjERISAhiYmJgYWEBd3d3HDp06LWvHRsbi86dO2PAgAHw8PCAm5sb7O3tJbaJiIhAbm4uevXqxXVPW1hYYM2aNYiPj4eNjQ3Onz/fqMKnpqaGtLQ0dO/eHZ6enrCwsICvry/Ky8vbbJpnRUVFxMfHw9nZGba2tli3bh1iY2MRFhbWJq/XUjTXNyF8oLm+60RzfTfO1KlT8fTpU+zfv5/vKKQBNNc3IYQQ8gagQk0IIYQIGA0mI4QQGfPq5CekY2vWEfXx48dbOwchhBBC6tCsQu3u7o5evXrhm2++QX5+fmtnIoQQQsj/16xCfffuXfj7+2Pfvn3o2bMn3NzcsHfv3tfOXEMIIY3xhl2MQjqo1voeN6tQ6+rqIiAgAFevXsUff/yBPn364Msvv4SRkRFmz56N9PT0VglHCHmz1E6tST/6SUdQVlYGQHI62OZo8WAye3t7GBoaokuXLli6dCkSExOxZs0aODs7IyEhAW+//XZLX4IQ8oZQUFCAmpoaioqKoKioCDk5ujCFyB7GGMrKyvDgwQNoa2tLze3eVM0u1FVVVThw4AASExORnJwMR0dHfP/99/Dy8kJRURGCg4Mxfvx43Lhxo0UBCSFvDpFIhK5du+L27du4c+cO33EIaRFtbe1mLQX6qmYV6lmzZmHXrl1gjOGzzz7DsmXL8M4773CPd+rUCd999x2MjIxaHJAQ8mZRUlJC7969qfubyDRFRcUWH0nXalahvnHjBv7zn//A09Oz3pVGdHV16TIuQkizyMnJ0RSihPx/zToBFBYWhvHjx0sV6erqaqSlpQF4ca6pqcurEUIIIURSswr1sGHD8PjxY6n2Z8+eYdiwYS0ORQghhJAXmlWoX14Y/GWPHj1Cp06dWhyKEEIIIS806Ry1p6cngBcjM6dOnSrR9V1TU4Nr165hwIABrZuQEEIIeYM1qVBrab1YQ5cxBg0NDaiqqnKPKSkp4d1334Wfn1/rJiSEEELeYE0q1Js2bQIAmJqaIigoiLq5CSGEkDbW7FHfrVWk4+PjYWpqChUVFTg5OeH8+fMNbv/06VPMnDkTXbt2hbKyMvr06YPffvutVbIQQgghQtPoI2p7e3ukpKSgc+fOsLOzq3MwWa3Lly836jn37NmDwMBAJCQkwMnJCXFxcXBzc0NmZib09fWltq+srMQHH3wAfX197Nu3D8bGxrhz5w60tbUb+zYIIYQQmdLoQj1mzBhu8NjYsWNb5cVjY2Ph5+cHHx8fAEBCQgIOHTqExMRELFy4UGr7xMREPH78GGfOnOEmOTc1NW2VLIQQQogQiRhP68lVVlZCTU0N+/btkyj8U6ZMwdOnT3HgwAGpfUaOHAkdHR2oqanhwIED0NPTw8SJE7FgwYJ6p2qrqKhARUUFd7+4uBgmJiZ49uwZNDU1W/19EdIoS7QaeOxZ++UghPCiuLgYWlpajapFvC1N8/DhQ9TU1MDAwECi3cDAAIWFhXXuk5OTg3379qGmpga//fYbQkJCsGLFCnzzzTf1vk5MTAy0tLS4m4mJSau+D0IIIaQtNbrru3Pnzg2el35ZXbOWtQaxWAx9fX388MMPkJeXh4ODA+7evYvly5cjLCyszn0WLVqEwMBA7n7tETUhhBAiCxpdqOPi4lr1hXV1dSEvL4/79+9LtN+/f7/eZcG6du0qtSKJhYUFCgsLUVlZCSUlJal9lJWV6104hBBCCBG6RhfqKVOmtOoLKykpwcHBASkpKdw5arFYjJSUFPj7+9e5z8CBA7Fz506IxWJuQflbt26ha9eudRZpQgghRNY1+hx1cXGxxN8N3RorMDAQ69evx5YtW5CRkYEvvvgCpaWl3Chwb29vLFq0iNv+iy++wOPHjzFnzhzcunULhw4dQnR0NGbOnNno1ySEEEJkSZPOURcUFEBfXx/a2tp1nq+uXayjpqamUc85YcIEFBUVITQ0FIWFhbC1tcWRI0e4AWZ5eXnckTMAmJiY4Pfff0dAQACsra1hbGyMOXPmYMGCBY19G4QQQohMafTlWSdOnMDAgQOhoKCAEydONLitkNehbsqQeEJawnThoXofy1WZWP+OdHkWIR1eU2pRo4+oXy6+Qi7EhBBCSEfSpEU5XvbkyRNs3LgRGRkZAABLS0v4+PhAR0en1cIRQgghb7pmTXiSlpYGU1NTrF69Gk+ePMGTJ0+wevVqmJmZIS0trbUzEkIIIW+sZh1Rz5w5ExMmTMDatWu5a5pramrw5ZdfYubMmfjzzz9bNSQhhBDypmrWEXVWVha++uoriYlH5OXlERgYiKysrFYLRwghhLzpmlWo7e3tuXPTL8vIyICNjU2LQxFCCCHkhUZ3fV+7do37e/bs2ZgzZw6ysrLw7rvvAgDOnTuH+Ph4LF26tPVTEkIIIW+oRl9HLScnB5FIhNdt3pQJT/hA11GT9kLXURNC6tMm11Hfvn27xcEIIYQQ0jSNLtQ9evRoyxyEEEIIqUOzJzwBgBs3biAvLw+VlZUS7aNHj25RKEIIIYS80KxCnZOTg48++gh//vmnxHnr2oU6hHyOmhBCCJElzbo8a86cOTAzM8ODBw+gpqaGv/76C2lpaXB0dERqamorRySEEELeXM06oj579iz++9//QldXF3JycpCTk8OgQYMQExOD2bNn48qVK62dkxBCCHkjNeuIuqamBhoaGgAAXV1d3Lt3D8CLAWeZmZmtl44QQgh5wzXriPqdd95Beno6zMzM4OTkhGXLlkFJSQk//PADevbs2doZCSGEkDdWswp1cHAwSktLAQARERH48MMPMXjwYHTp0gV79uxp1YCEEELIm6xZhdrNzY3729zcHDdv3sTjx4/RuXNnbuQ3IYQQQlquRddRA0B+fj4AwMTEpMVhCCGEECKpWYPJqqurERISAi0tLZiamsLU1BRaWloIDg5GVVVVa2ckhBBC3ljNOqKeNWsWkpKSsGzZMjg7OwN4ccnWkiVL8OjRI6xdu7ZVQxJCCCFvqmYV6p07d2L37t0YMWIE12ZtbQ0TExN4eXlRoSaEEEJaSbO6vpWVlWFqairVbmZmBiUlpZZmIoQQQsj/16xC7e/vj8jISFRUVHBtFRUViIqKgr+/f6uFI4QQQt50je769vT0lLh/7NgxdOvWDTY2NgCA9PR0VFZW4v3332/dhIQQQsgbrNGFWktLS+L+xx9/LHGfLs8ihBBCWl+jC/WmTZvaMgchhBBC6tCiCU+Kioq4RTjeeust6OnptUooQgghhLzQrMFkpaWlmDZtGrp27YohQ4ZgyJAhMDIygq+vL8rKylo7IyGEEPLGalahDgwMxIkTJ/Drr7/i6dOnePr0KQ4cOIATJ07gq6++avLzxcfHw9TUFCoqKnBycsL58+cbtd/u3bshEokwduzYJr8mIYQQIguaVah/+uknbNy4ESNGjICmpiY0NTUxcuRIrF+/Hvv27WvSc+3ZsweBgYEICwvD5cuXYWNjAzc3Nzx48KDB/XJzcxEUFITBgwc35y0QQgghMqFZhbqsrAwGBgZS7fr6+k3u+o6NjYWfnx98fHxgaWmJhIQEqKmpITExsd59ampqMGnSJISHh9P614QQQjq0ZhVqZ2dnhIWFoby8nGt7/vw5wsPDubm/G6OyshKXLl2Cq6vr/wLJycHV1RVnz56td7+IiAjo6+vD19f3ta9RUVGB4uJiiRshhBAiK5o16jsuLg7u7u5SE56oqKjg999/b/TzPHz4EDU1NVJH5wYGBrh582ad+5w6dQobN27E1atXG/UaMTExCA8Pb3QmQgghREiaVaitrKzw999/Y8eOHVxB9fLywqRJk6CqqtqqAV/277//4rPPPsP69euhq6vbqH0WLVqEwMBA7n5xcTFNzkIIIURmNLlQV1VVoW/fvjh48CD8/Pxa9OK6urqQl5fH/fv3Jdrv378PQ0NDqe2zs7ORm5sLDw8Prk0sFgMAFBQUkJmZiV69eknso6ysDGVl5RblJIQQQvjS5HPUioqKEuemW0JJSQkODg5ISUnh2sRiMVJSUuo81923b1/8+eefuHr1KncbPXo0hg0bhqtXr9KRMiGEkA6nWV3fM2fOxLfffosNGzZAQaFFk5shMDAQU6ZMgaOjI/r374+4uDiUlpbCx8cHAODt7Q1jY2PExMRARUUF77zzjsT+2traACDVTgghhHQEzaqyFy5cQEpKCo4ePQorKyt06tRJ4vGkpKRGP9eECRNQVFSE0NBQFBYWwtbWFkeOHOEGmOXl5UFOrlmD0wkhhBCZ16xCra2tLbV6Vkv4+/vXu451ampqg/tu3ry51XIQQgghQtOkQi0Wi7F8+XLcunULlZWVeO+997BkyZI2HelNCCGEvMma1KccFRWFxYsXQ11dHcbGxli9ejVmzpzZVtkIIYSQN16Tjqi3bt2KNWvW4PPPPwcAHDt2DKNGjcKGDRvoPDIhhHRwpgsP1dmeu3RUOyd5szSpuubl5WHkyJHcfVdXV4hEIty7d6/VgxFCCCGkiYW6uroaKioqEm2Kioqoqqpq1VCEEEIIeaFJXd+MMUydOlVipq/y8nLMmDFD4hKtplyeRQghhJD6NalQT5kyRapt8uTJrRaGEEIIIZKaVKg3bdrUVjkIIYQQUgcaqk0IIYQIGBVqQgghRMCoUBNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBIwKNSGEECJgVKgJIYQQAaNCTQghhAgYFWpCCCFEwKhQE0IIIQJGhZoQQggRMCrUhBBCiIBRoSaEEEIEjAo1IYQQImBUqAkhhBABo0JNCCGECJgC3wEIIZKstljV+9ifU/5sxySEECGgI2pCCCFEwKhQE0IIIQImiEIdHx8PU1NTqKiowMnJCefPn6932/Xr12Pw4MHo3LkzOnfuDFdX1wa3J4QQQmQZ7+eo9+zZg8DAQCQkJMDJyQlxcXFwc3NDZmYm9PX1pbZPTU2Fl5cXBgwYABUVFXz77bcYPnw4/vrrLxgbG/PwDgghhNSHxly0HO9H1LGxsfDz84OPjw8sLS2RkJAANTU1JCYm1rn9jh078OWXX8LW1hZ9+/bFhg0bIBaLkZKS0s7JCSGEkLbHa6GurKzEpUuX4OrqyrXJycnB1dUVZ8+ebdRzlJWVoaqqCjo6Om0VkxBCCOENr13fDx8+RE1NDQwMDCTaDQwMcPPmzUY9x4IFC2BkZCRR7F9WUVGBiooK7n5xcXHzAxNCCCHtjPeu75ZYunQpdu/ejZ9//hkqKip1bhMTEwMtLS3uZmJi0s4pCSGEkObjtVDr6upCXl4e9+/fl2i/f/8+DA0NG9z3u+++w9KlS3H06FFYW1vXu92iRYvw7Nkz7pafn98q2QkhhJD2wGuhVlJSgoODg8RAsNqBYc7OzvXut2zZMkRGRuLIkSNwdHRs8DWUlZWhqakpcSOEEEJkBe+XZwUGBmLKlClwdHRE//79ERcXh9LSUvj4+AAAvL29YWxsjJiYGADAt99+i9DQUOzcuROmpqYoLCwEAKirq0NdXZ2390EIIYS0Bd4L9YQJE1BUVITQ0FAUFhbC1tYWR44c4QaY5eXlQU7ufwf+a9euRWVlJcaNGyfxPGFhYViyZEl7RieEEELaHO+FGgD8/f3h7+9f52OpqakS93Nzc9s+ECGEECIQMj3qmxBCCOnoqFATQgghAkaFmhBCCBEwQZyjfhPRRPWEEEIag46oCSGEEAGjQk0IIYQIGBVqQgghRMCoUBNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBIwKNSGEECJgVKgJIYQQAaNCTQghhAgYFWpCCCFEwKhQE0IIIQJGi3IQQlqMFpkhHYnQvs90RE0IIYQIGBVqQgghRMCo65s0mtC6gwgh5E1AR9SEEEKIgFGhJoQQQgSMur5byHThoXofy106qh2TEEII6YjoiJoQQggRMCrUhBBCiIBR1zfp0GikOqmPLH43ZDEzaTk6oiaEEEIEjAo1IYQQImBUqAkhhBABE0Shjo+Ph6mpKVRUVODk5ITz5883uP2PP/6Ivn37QkVFBVZWVvjtt9/aKSkhhBDSvngv1Hv27EFgYCDCwsJw+fJl2NjYwM3NDQ8ePKhz+zNnzsDLywu+vr64cuUKxo4di7Fjx+L69evtnJwQQghpe7wX6tjYWPj5+cHHxweWlpZISEiAmpoaEhMT69x+1apVcHd3x7x582BhYYHIyEjY29vj+++/b+fkhBBCSNvj9fKsyspKXLp0CYsWLeLa5OTk4OrqirNnz9a5z9mzZxEYGCjR5ubmhv3797dlVEIIIfVZolX/Y2bd2y9HB8VroX748CFqampgYGAg0W5gYICbN2/WuU9hYWGd2xcWFta5fUVFBSoqKrj7z549AwAUFxe3JDpHXFFW72MNvUbN85pm7dca3gn7vd7Hroe71fsYn5mbi8/MDX43RKzex/j+nOv7ftB3g398Z67vO03f56arfR7G6v/sOIxHd+/eZQDYmTNnJNrnzZvH+vfvX+c+ioqKbOfOnRJt8fHxTF9fv87tw8LCGAC60Y1udKMb3QR3y8/Pf22t5PWIWldXF/Ly8rh//75E+/3792FoaFjnPoaGhk3aftGiRRJd5WKxGI8fP0aXLl0gEola+A4kFRcXw8TEBPn5+dDU1GzV524rlLl9UOb2QZnbB2VuOcYY/v33XxgZGb12W14LtZKSEhwcHJCSkoKxY8cCeFFIU1JS4O/vX+c+zs7OSElJwdy5c7m25ORkODs717m9srIylJWVJdq0tbVbI369NDU1BfFFaArK3D4oc/ugzO2DMreMlpZWo7bjfa7vwMBATJkyBY6Ojujfvz/i4uJQWloKHx8fAIC3tzeMjY0RExMDAJgzZw5cXFywYsUKjBo1Crt378bFixfxww8/8Pk2CCGEkDbBe6GeMGECioqKEBoaisLCQtja2uLIkSPcgLG8vDzIyf3vKrIBAwZg586dCA4OxuLFi9G7d2/s378f77zzDl9vgRBCCGkzvBdqAPD396+3qzs1NVWqbfz48Rg/fnwbp2o6ZWVlhIWFSXW1Cxllbh+UuX1Q5vZBmduXiLHGjA0nhBBCCB94n5mMEEIIIfWjQk0IIYQIGBVqQgghRMCoUBNCCCECRoW6maqrq7F161apWdIIIYSQ1kSjvltATU0NGRkZ6NGjB99RGm3KlCnw9fXFkCFD+I7SJD179sSFCxfQpUsXifanT5/C3t4eOTk5PCX7n19++aXR244ePboNk7zZampq8Oeff6JHjx7o3Lkz33FkVlMWnxDKTF+vSktLa/BxWfl3UBDXUcuq/v374+rVqzJVqJ89ewZXV1f06NEDPj4+mDJlCoyNjfmO9Vq5ubmoqZFe0aaiogJ3797lIZG02mlwa4lEIomVcV6eW76u9yIEW7Zsga6uLkaNGgUAmD9/Pn744QdYWlpi165dgvyuz507F1ZWVvD19UVNTQ1cXFxw5swZqKmp4eDBgxg6dCjfEWWStrZ2o9dDEOr3ua7/72Xhv8NXUaFugS+//BKBgYHIz8+Hg4MDOnXqJPG4tbU1T8nqt3//fhQVFWHbtm3YsmULwsLC4OrqCl9fX4wZMwaKiop8R5Tw8lHq77//LjE3bk1NDVJSUmBqaspDMmlisZj7+9ixY1iwYAGio6O5eejPnj2L4OBgREdH8xXxtaKjo7F27VoAL/LGx8dj5cqVOHjwIAICApCUlMRzQmn79u3D5MmTAQC//vorbt++jZs3b2Lbtm34+uuvcfr0aZ4T1m3fvn3Yu3cv8vLyUFlZKfHY5cuXeUr1P8ePH+f+zs3NxcKFCzF16lSJ7/OWLVu46Z2F6MmTJxL3q6qqcOXKFYSEhCAqKoqnVM3w2vW1SL1EIpHUTU5OjvtfWXDp0iXm7+/PVFRUmK6uLps7dy67desW37E4dX3GtTclJSXWp08f9uuvv/IdU8rbb7/NTp48KdWelpbG+vbty0OixlFVVWV37txhjDE2f/589tlnnzHGGLt+/TrT1dXlM1q9lJWVuaUC/fz82Jw5cxhjjOXk5DANDQ0ek9Vv1apVTF1dnfn7+zMlJSX2+eefM1dXV6alpcUWL17Mdzwp7733ntTywowxtmPHDubi4tL+gVooNTWV2dvb8x2j0WgwWQvcvn1b6paTk8P9r9AVFBQgOTkZycnJkJeXx8iRI/Hnn3/C0tISK1eu5DsegBdHqWKxGD169EBRURF3XywWo6KiApmZmfjwww/5jiklOzu7zlXatLS0kJub2+55GktdXR2PHj0CABw9ehQffPABAEBFRQXPnz/nM1q9DAwMcOPGDdTU1ODIkSNc5rKyMsjLy/Ocrm5r1qzBDz/8gP/85z9QUlLC/PnzkZycjNmzZ+PZs2d8x5Ny9uxZODo6SrU7Ojri/PnzPCRqGQMDA2RmZvIdo/H4/qVA2ldlZSXbt28fGzVqFFNUVGQODg5s7dq17NmzZ9w2SUlJTFtbm8eUkiorK9l7770nqCP91xk8eDD74IMPWGFhIddWWFjIhg8fzoYMGcJjsoZNnDiR2dvbM19fX6ampsYePnzIGGPswIED7O233+Y5Xd3CwsKYlpYW69u3L+vevTsrLy9njDG2ceNG9u677/Kcrm6qqqosNzeXMcaYnp4eu3r1KmOMsVu3bjEdHR0+o9WpT58+bN68eVLt8+bNY3369OEhUeOkp6dL3K5evcoOHz7MXFxc2MCBA/mO12h0jrqFtm3bhoSEBNy+fRtnz55Fjx49EBcXBzMzM4wZM4bveFK6du0KsVgMLy8vnD9/Hra2tlLbDBs2rM3X7G4KRUVFXLt2je8YTbJx40Z4enqie/fuMDExAQDk5+dzq70JVXx8PIKDg5Gfn4+ffvqJG2V/6dIleHl58ZyubkuWLME777yD/Px8jB8/nlt0QV5eHgsXLuQ5Xd0MDQ3x+PFj9OjRA927d8e5c+dgY2OD27dvSwxAFIqVK1fi448/xuHDh+Hk5AQAOH/+PP7++2/89NNPPKern62trdSgTgB49913kZiYyFOqpqPLs1pg7dq1CA0Nxdy5cxEVFYXr16+jZ8+e2Lx5M7Zs2SIxGEMotm3bhvHjx0NFRYXvKE0SEBAAZWVlLF26lO8ojcYYQ3JyMm7evAkAsLCwgKura6NH0pKmKy8vl4nv9vTp02FiYoKwsDDEx8dj3rx5GDhwIC5evAhPT09s3LiR74hS/vnnH6xduxYZGRkAXnyfZ8yYwf0QFaI7d+5I3JeTk4Oenp5MfEdeRoW6BSwtLREdHY2xY8dCQ0MD6enp6NmzJ65fv46hQ4fi4cOHfEeUUFVVBVVVVVy9elXm1u+eNWsWtm7dit69e9c5wj42NpanZNJk+XMGgJMnT2LdunXIycnBjz/+CGNjY2zbtg1mZmYYNGgQ3/Gk1NTUIDo6GgkJCbh//z5u3bqFnj17IiQkBKampvD19eU7opTacRYKCi86NXfv3o0zZ86gd+/e+Pzzz6GkpMRzwv+pqqqCu7s7EhIS0Lt3b77jvJFoMFkL3L59G3Z2dlLtysrKKC0t5SFRwxQVFdG9e3eZuXbwZdevX4e9vT00NDRw69YtXLlyhbtdvXqV73gSZPlz/umnn+Dm5gZVVVVcvnwZFRUVAF5cfy/Uy8qioqKwefNmLFu2TKLAvfPOO9iwYQOPyeonJyfHFWkA+PTTT7F69WrMmjVLUEUakM1TTy87ceIEPDw8YG5uDnNzc4wePRonT57kO1bT8Hh+XOZZWFiw/fv3M8YYU1dXZ9nZ2YwxxlavXs3s7Oz4jFavDRs2sJEjR7JHjx7xHaVDk9XP2dbWlm3ZsoUxJvmdvnz5MjMwMOAzWr169erFjh07xhiTzJyRkSGoQZEvMzMzY1OnTuUGvtUqKipiZmZmPKWq39y5c9mCBQv4jtFk27ZtYwoKCuyTTz5hq1atYqtWrWKffPIJU1RUZDt27OA7XqPRYLIWCAwMxMyZM1FeXg7GGM6fP49du3YhJiZGsL/kv//+e2RlZcHIyAg9evSQ6kIWwkQLr/PPP/8AALp168ZzkvrJ6uecmZlZ57SKWlpaePr0afsHaoS7d+/C3Nxcql0sFqOqqoqHRK+Xm5sLBQUFDB48GL/88gsMDQ0BvOjGf/W8qhBUV1cjMTERx44dE/ypp5dFRUVh2bJlCAgI4Npmz56N2NhYREZGYuLEiTymazwq1C0wffp0qKqqIjg4GGVlZZg4cSKMjIywatUqfPrpp3zHq9Or01zKCrFYjG+++QYrVqxASUkJAEBDQwNfffUVvv76a8jJCessjqx+zoaGhsjKypKa7e3UqVPo2bMnP6Few9LSEidPnpSa3nTfvn11npoSApFIhCNHjiAoKAgODg7Yv38/+vXrx3esetWeegKAW7duSTwm5MGROTk58PDwkGofPXo0Fi9ezEOiZuL7kL6jKC0tZffv3+c7Roe1cOFCpqenx9asWcNdExkfH8/09PQEOZOTrIqOjmaWlpbs3LlzTENDg508eZJt376d6enpsdWrV/Mdr0779+9nWlpabOnSpUxNTY0tX76cTZ8+nSkpKbGjR4/yHa9OIpGI+/di4cKFTFVVlW3bto0VFhbKzKyGsqBXr14sISFBqn3t2rXM3Nych0TNQ4W6BcrKylhpaSl3Pzc3l61cuZL9/vvvPKZ6vSdPnrD169ezhQsXcudQL126xP755x+ek9Wva9eu7MCBA1Lt+/fvZ0ZGRjwk6pjEYjH75ptvWKdOnbipWlVUVFhwcDDf0RqUlpbGXF1dmZ6eHlNVVWUDBw4U9H+HcnJyEj/st23bxlRUVJiPjw8V6la0Zs0apqSkxGbMmMG2bt3Ktm7dyj7//HOmrKxcZwEXKro8qwWGDx8OT09PzJgxA0+fPsVbb70FJSUlPHz4ELGxsfjiiy/4jijl2rVrcHV15aayzMzMRM+ePREcHIy8vDxs3bqV74h1UlFRwbVr19CnTx+J9szMTNja2gpuesuamhqsXLmy3kUXHj9+zFOyxqmsrERWVhZKSkpgaWkJdXV1viN1KHJycigsLIS+vj7XdvbsWXz00UcoKioS5BUDFy9erPf7LMTFWmr9/PPPWLFihcT13/PmzRPkhFT14vuXgizr0qULu379OmOMsfXr1zNra2tWU1PD9u7dK9iFF95//31uKsCXR8iePn2a9ejRg8dkDevfvz+bNWuWVLu/vz9zcnLiIVHDQkJCWNeuXdl3333HVFRUWGRkJPP19WVdunRhq1at4jteh+Lr68uOHz/Od4xWUVhYyFJTU/mOIWXXrl1MUVGRffjhh0xJSYl9+OGHrE+fPkxLS4tNnTqV73j18vb2ZidOnOA7RotRoW6Bl1caGj9+PFuyZAljjLG8vDymqqrKZ7R6aWpqsqysLMaYZKHOzc1lysrKfEZrUGpqKuvUqROzsLBg06ZNY9OmTWMWFhZMXV2dpaWl8R1PSs+ePdnBgwcZYy8+59rPfNWqVczLy4vPaA0qKSlhwcHBzNnZmfXq1YuZmZlJ3IRo9OjRTFlZmXXr1o0FBQWxK1eu8B3ptcLDw1lKSopUe0lJCQsPD+chUcOsrKzY999/zxj7378bYrGY+fn5sdDQUJ7T1W/MmDFMUVGRmZubs6ioKHb37l2+IzULFeoWsLKyYqtWrWJ5eXlMU1OTnTlzhjHG2MWLFwV7zamenh67fPkyY0yyUB89epR169aNz2ivdffuXbZ48WLm6enJPD092ddffy3Y//DU1NS4H3GGhobs0qVLjDHGsrOzmaamJp/RGvTpp5+yrl27svnz57OVK1eyuLg4iZtQPX78mK1bt465uLgwOTk5ZmlpyaKiotjt27f5jlan2mVaV6xYIdEu1MFkampq3Gepo6PDrl27xhhj7MaNG8zQ0JDHZK/34MEDtmLFCmZtbc0UFBSYu7s727t3L6usrOQ7WqNRoW6BH3/8kSkqKjI5OTnm6urKtUdHRzN3d3cek9XP19eXjR07llVWVjJ1dXWWk5PD7ty5w+zs7Lh1fIXio48+4lb12rJli9TkEELWp08fdu7cOcYYYwMHDmQxMTGMMcZ2797N9PT0+IzWIC0tLXbq1Cm+Y7RIfn4+W7ZsGevbty+Tl5fnO06dRCIR2717N+vSpQubOnUqq6ioYIwJt1AbGxtzxdnKyopbm/rMmTOC/uH5qkuXLjF/f3+moqLCdHV12dy5c2ViVT4q1C1UUFDALl++zGpqari2P/74g2VkZPCYqn5Pnz5lrq6uTFtbm8nLyzMTExOmqKjIhgwZwkpKSviOJ0FRUZHdu3ePMSY9SlboFixYwKKiohhjL4qzgoICMzc3Z0pKSoKe4cnU1JTduHGD7xjNVllZyX7++Wf28ccfMxUVFcFeEVB7eVZWVhazsLBgzs7O7P79+4It1F5eXtzRf0REBNPT02PTp09nPXr0YB999BHP6Rrn3r17bOnSpeytt95inTp1Yt7e3uz9999nCgoKLDY2lu94DaJR361EFmbLetmpU6dw7do1lJSUwN7eHq6urnxHkmJtbQ17e3sMGzYMPj4+WL16NTQ1Nevc1tvbu53TNc25c+e4RRfqmoBBKLZv344DBw5gy5YtUFNT4ztOox0/fhw7d+7ETz/9BLFYDE9PT0yaNAnvvfeeICfkkJeXR0FBAfT19VFcXIxPPvkEf/31FxISEjB69GjBjfp+/PgxysvLYWRkBLFYjGXLlnHf5+DgYHTu3JnviHWqqqrCL7/8gk2bNuHo0aOwtrbG9OnTMXHiRO7fkp9//hnTpk3DkydPeE5bPyrULSBrs2UBL9ZEFvKydC87ffo0vvrqK2RnZ+Px48fQ0NCo8x9dkUgk+MudhMzOzk7ic83KygJjDKamplBUVJTYVohTnxobG+Px48dwd3fHpEmT4OHhwa1JLVSvXp4lFosxd+5crF27FmKxWHCFWlbp6upCLBbDy8sLfn5+sLW1ldrm6dOnsLOzw+3bt9s/YCPRFKIt8PXXX2Pjxo1YunQpBg4cCODFkeqSJUtQXl6OqKgonhNKMzU1xaBBgzB58mSMGzdOsL+EAWDgwIE4d+4cgBf/sN26dUviulMh6969O4YOHQoXFxcMHToUvXr14jtSvWR1utNaS5Yswfjx46Gtrc13lEbbtGkTtLS0uPtycnJYvXo17OzskJaWxmOyunl7e2PYsGEYMmSIoL/Lr1q5ciXGjx/f4PrT2tragi7SAB1Rt4iRkRHXVfWyAwcO4Msvv8Tdu3d5Sla/K1euYOfOndi9ezeKiorg7u6OyZMnC/IoxNPTE5s3b4ampia2bNmCTz75BKqqqnzHapTt27cjLS0NqampyMrKgrGxMVxcXLjCTev6tg1ZOwUlK6ZPn460tDSJ73LtD1H6Lrc9KtQtIGuzZb2MMYbU1FSp83qJiYl8R+MoKSnhzp076Nq1q8Q5PVlTUFCAEydO4ODBg9izZ4+guzYvXLgAsVgMJycnifY//vgD8vLycHR05ClZ/WTlFNTq1avxf//3f1BRUcHq1avr3U4kEmHWrFntmKzx7t69i7S0NJw4cQInTpzArVu30LVrV+4HEmkbVKhbwMnJCU5OTlL/0c2aNQsXLlzgum2F7vLly/D19cW1a9cEVUBkfTBZWVkZTp06hdTUVBw/fhxXrlyBhYUFhg4dipUrV/Idr079+/fH/PnzMW7cOIn2pKQkfPvtt/jjjz94Sla/RYsWYePGjQgPD5c6BeXn5yeYU1BmZma4ePEiunTpAjMzs3q3E4lEyMnJacdkjVf7nT5+/DhSU1Nx+fJlWFpa4sqVK3xH69CoULfAiRMnMGrUKHTv3h3Ozs4AXszXm5+fj99++w2DBw/mOWH9/vnnH+zcuRM7d+7E9evX4ezsjEmTJmHGjBl8R+OcOXMGgYGBMjmYbMCAARKF2cXFBUOGDBH0mAAAUFdXx7Vr16SWtLx9+zasra3x77//8pSsfrJ4Cupltf8EC3F0eq3FixcjNTWV+07Xdn3Lwne6I6BC3UL37t1DfHw8bt68CeDFhO9ffvkljIyMeE5Wt3Xr1mHnzp04deoULCwsMGnSJEycOFFqLV+hqWsRAyHT0dGBnJwchg8fjqFDh2Lo0KFSp0iEqEuXLjh48CD3w7PWmTNnMGrUKEFewiKrp6A2btyIlStX4u+//wYA9O7dG3PnzsX06dN5TiZNTk4Oenp6CAgIgKenp0x8lzsSKtRvGBMTE3h5eWHSpEmwsbHhO06j3blzB3l5eVi3bh1ycnLw448/wtjYGNu2bYOZmRkGDRrEd0QJjDH8+eefSE1NxYkTJ5CWlgYlJSW4uLhg2LBh8PPz4ztinby8vFBQUIADBw5wo5KfPn2KsWPHQl9fH3v37uU5oTRZPAUVGhqK2NhYzJo1S6I37vvvv0dAQAAiIiJ4TigpPT0dJ06cQGpqKk6ePMl9l2XpR6gso0LdRNeuXWv0ttbW1m2YpHkYYzh16pTMFLxaP/30Ez777DNMmjQJ27Ztw40bN9CzZ098//33+O233/Dbb7/xHbFejDFcunQJ33//PXbs2CHowWR3797FkCFD8OjRI9jZ2QEArl69CgMDAyQnJwvyGvz6TkHl5eXh8OHDgjwFpaenh9WrV8PLy0uifdeuXZg1axYePnzIU7LGSU9Px8qVKwX/fe4o6DrqJrK1tYVIJMLrft+IRCJBfnmTkpK4gnf58mVUVFQAAJ49e4bo6GjBFrxvvvkGCQkJ8Pb2xu7du7n2gQMH4ptvvuExWd0uX76M1NRUpKam4tSpU/j3339hZWWFWbNmwcXFhe949TI2Nsa1a9ewY8cOpKenQ1VVFT4+PvDy8pKa/EQoXFxckJmZibVr13JrDnt6egr6FFRVVVWdI+gdHBxQXV3NQ6KGMcZw5coVie90cXExrK2tBf197ijoiLqJ7ty50+hthXje187ODgEBAfD29oaGhgbS09PRs2dPXLlyBSNGjEBhYSHfEeukpqaGGzduwNTUVCJ3Tk4OLC0tUV5ezndECQoKCrCzs+OunR4yZIjEBBekdZWXl+PatWt48OABxGKxxGOvDjITglmzZkFRURGxsbES7UFBQXj+/Dni4+N5Sla3zp07o6SkBDY2NlyX9+DBg2VqkhlZRkfUTfRy8Y2JiYGBgQGmTZsmsU1iYiKKioqwYMGC9o73WpmZmRgyZIhUu5aWFp4+fdr+gRrJ0NAQWVlZMDU1lWg/deqU1AhlvtXU1CApKQmDBw+WyRGxf//9N44fP15n0QsNDeUpVf2OHDkCb29vPHr0SKqnS6g9W8CLwWRHjx7Fu+++C+DFtep5eXnw9vZGYGAgt92rxZwP27dvx+DBg+u9PJK0LSrULVA7gvpVb7/9Nj799FNBFmpZKngv8/Pzw5w5c5CYmAiRSIR79+7h7NmzCAoKQkhICN/xJMjLy+OTTz5BRkaGzBXq9evX44svvoCuri4MDQ0lLhkSiUSCLNSzZs3C+PHjERoaCgMDA77jNMr169dhb28PAMjOzgbwYl5qXV1dXL9+ndtOKJdsjRo1ivubZn/jQbus0dVBKSsrs5ycHKn27OxspqyszEOi14uOjmaWlpbs3LlzTENDg508eZJt376d6enpsdWrV/Mdr15isZh98803rFOnTkwkEjGRSMRUVFRYcHAw39Hq5ODgwI4dO8Z3jCbr3r07W7p0Kd8xmkRDQ4NlZWXxHaNDq6mpYeHh4UxTU5PJyckxOTk5pqWlxSIiIiSW+CVtgwp1C5ibm7Nt27ZJtW/dupWZmZnxkOj1ZK3gvaqiooL99ddf7I8//mD//vsv33HqdfjwYWZra8t+/fVXdu/ePfbs2TOJm1BpaGiw7OxsvmM0iY+PD9uwYQPfMTq0hQsXMj09PbZmzRqWnp7O0tPTWXx8PNPT02OLFy/mO16HR4PJWmDZsmVYtmwZli9fjvfeew8AkJKSgvnz5+Orr77CokWLeE5Yv8rKSmRlZaGkpASWlpZQV1fnO1KH8vL80i93XzLGBH3e1NfXF/369RPUDHWvU1ZWhvHjx0NPTw9WVlZSo9Nnz57NU7KOQ9Znf5N1dI66BebNm4dHjx7hyy+/RGVlJYAXsyQtWLBA0EUaeLHghaWlJd8xOqzjx4/zHaFZzM3NERISgnPnzslM0du1axeOHj0KFRUVpKamSp1XF2JmWfP48WP07dtXqr1v376Cm763I6Ij6lZQUlKCjIwMqKqqonfv3oJbLpKQxpLFxSIMDQ0xe/ZsLFy4UDArZXU0sjj7W0dChZqQNvL06VNs3LiRm4Tj7bffxrRp0+h66lamo6ODCxcuoFevXnxH6bBkeQGijoAKNSFt4OLFi3Bzc4Oqqir69+8P4MVaz8+fP8fRo0e5S3OEIDAwEJGRkejUqZPE9buvEolEWLFiRTsma5yAgADo6elh8eLFfEfpsPLy8qCgoFDnAkTV1dXo3r07zwk7NirUhLSBwYMHw9zcHOvXr4eCwouhINXV1Zg+fTpycnKQlpbGc8L/GTZsGH7++Wdoa2tj2LBh9W4nEonw3//+tx2TNc7s2bOxdetW2NjYwNraWuq8uhAmDJF18vLyKCgokFq97tGjR9DX1xfs4MiOggo1IW1AVVUVV65ckRqAc+PGDTg6OqKsrIynZB2PLP64kDX1LTN7584dWFpaorS0lKdkbwYa9U1IG9DU1EReXp5Uoc7Pz4eGhgZPqTomWR1hLwtqT4XUzkqnpqbGPVZTU4M//vgDtra2PKV7c1ChJqQNTJgwAb6+vvjuu+8wYMAAAMDp06cxb948qaUNCRGqK1euAPjf+upKSkrcY0pKSrCxsUFQUBBf8d4Y1PVNSCu5du0a3nnnHcjJyaGyshLz5s1DQkICt2yhoqIivvjiCyxdupQu4SMyxcfHB6tWraJFOXhChZqQVvLygJuePXviwoULUFVV5RZd6NWrl0TXISGENAZ1fRPSSrS1tXH79m3o6+sjNzcXYrEYampqsLKy4jsaIUSGUaEmpJV8/PHHcHFxQdeuXSESieDo6Ah5efk6txXiDF+EEGGiQk1IK/nhhx/g6emJrKwszJ49G35+fjTCmxDSYnSOmpA24OPjg9WrV1OhJoS0GBVqQgghRMBoqRlCCCFEwKhQE0IIIQJGhZoQQggRMCrUhBBCiIBRoSaEEEIEjAo1IYQQImBUqAkhhBABo0JNCCGECNj/AziNpZr5Sbj4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]  # Original, higher, and lower temperature\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], \n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406800f3",
   "metadata": {
    "papermill": {
     "duration": 0.040372,
     "end_time": "2024-05-21T10:07:21.454291",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.413919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "70ebb1de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:21.538249Z",
     "iopub.status.busy": "2024-05-21T10:07:21.537578Z",
     "iopub.status.idle": "2024-05-21T10:07:21.546915Z",
     "shell.execute_reply": "2024-05-21T10:07:21.545955Z"
    },
    "papermill": {
     "duration": 0.053723,
     "end_time": "2024-05-21T10:07:21.548842",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.495119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a55eab11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:21.632869Z",
     "iopub.status.busy": "2024-05-21T10:07:21.632510Z",
     "iopub.status.idle": "2024-05-21T10:07:21.641763Z",
     "shell.execute_reply": "2024-05-21T10:07:21.640809Z"
    },
    "papermill": {
     "duration": 0.053694,
     "end_time": "2024-05-21T10:07:21.643686",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.589992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abd5ce02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:21.726101Z",
     "iopub.status.busy": "2024-05-21T10:07:21.725790Z",
     "iopub.status.idle": "2024-05-21T10:07:21.731425Z",
     "shell.execute_reply": "2024-05-21T10:07:21.730477Z"
    },
    "papermill": {
     "duration": 0.049036,
     "end_time": "2024-05-21T10:07:21.733383",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.684347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7497ad5",
   "metadata": {
    "papermill": {
     "duration": 0.04105,
     "end_time": "2024-05-21T10:07:21.815087",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.774037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0975a98c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:21.898458Z",
     "iopub.status.busy": "2024-05-21T10:07:21.897750Z",
     "iopub.status.idle": "2024-05-21T10:07:21.906138Z",
     "shell.execute_reply": "2024-05-21T10:07:21.905232Z"
    },
    "papermill": {
     "duration": 0.052201,
     "end_time": "2024-05-21T10:07:21.908045",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.855844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature, top_k=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e80de5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:21.993077Z",
     "iopub.status.busy": "2024-05-21T10:07:21.992190Z",
     "iopub.status.idle": "2024-05-21T10:07:23.344120Z",
     "shell.execute_reply": "2024-05-21T10:07:23.343128Z"
    },
    "papermill": {
     "duration": 1.396849,
     "end_time": "2024-05-21T10:07:23.346570",
     "exception": false,
     "start_time": "2024-05-21T10:07:21.949721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to go a little wild--I felt nervous and uncertain.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff2fb3",
   "metadata": {
    "papermill": {
     "duration": 0.040941,
     "end_time": "2024-05-21T10:07:23.431841",
     "exception": false,
     "start_time": "2024-05-21T10:07:23.390900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fortunately, saving a PyTorch model is relatively straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79a999b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:23.516473Z",
     "iopub.status.busy": "2024-05-21T10:07:23.515722Z",
     "iopub.status.idle": "2024-05-21T10:07:24.211771Z",
     "shell.execute_reply": "2024-05-21T10:07:24.210725Z"
    },
    "papermill": {
     "duration": 0.740908,
     "end_time": "2024-05-21T10:07:24.214138",
     "exception": false,
     "start_time": "2024-05-21T10:07:23.473230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3d06330",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:24.298220Z",
     "iopub.status.busy": "2024-05-21T10:07:24.297861Z",
     "iopub.status.idle": "2024-05-21T10:07:26.330483Z",
     "shell.execute_reply": "2024-05-21T10:07:26.329497Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.076804,
     "end_time": "2024-05-21T10:07:26.332554",
     "exception": false,
     "start_time": "2024-05-21T10:07:24.255750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91984d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:26.420192Z",
     "iopub.status.busy": "2024-05-21T10:07:26.419533Z",
     "iopub.status.idle": "2024-05-21T10:07:29.200579Z",
     "shell.execute_reply": "2024-05-21T10:07:29.199716Z"
    },
    "papermill": {
     "duration": 2.827887,
     "end_time": "2024-05-21T10:07:29.202845",
     "exception": false,
     "start_time": "2024-05-21T10:07:26.374958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec31b76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:29.288373Z",
     "iopub.status.busy": "2024-05-21T10:07:29.287756Z",
     "iopub.status.idle": "2024-05-21T10:07:33.379322Z",
     "shell.execute_reply": "2024-05-21T10:07:33.378294Z"
    },
    "papermill": {
     "duration": 4.138053,
     "end_time": "2024-05-21T10:07:33.383367",
     "exception": false,
     "start_time": "2024-05-21T10:07:29.245314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a32e888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:33.487871Z",
     "iopub.status.busy": "2024-05-21T10:07:33.487487Z",
     "iopub.status.idle": "2024-05-21T10:07:48.665514Z",
     "shell.execute_reply": "2024-05-21T10:07:48.664283Z"
    },
    "papermill": {
     "duration": 15.225837,
     "end_time": "2024-05-21T10:07:48.667926",
     "exception": false,
     "start_time": "2024-05-21T10:07:33.442089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow>=2.15.0  tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34634739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:48.754874Z",
     "iopub.status.busy": "2024-05-21T10:07:48.753795Z",
     "iopub.status.idle": "2024-05-21T10:07:48.931275Z",
     "shell.execute_reply": "2024-05-21T10:07:48.930292Z"
    },
    "papermill": {
     "duration": 0.222636,
     "end_time": "2024-05-21T10:07:48.933404",
     "exception": false,
     "start_time": "2024-05-21T10:07:48.710768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7fd1a043f430>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2cbc16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:07:49.018895Z",
     "iopub.status.busy": "2024-05-21T10:07:49.018229Z",
     "iopub.status.idle": "2024-05-21T10:08:17.703951Z",
     "shell.execute_reply": "2024-05-21T10:08:17.702803Z"
    },
    "papermill": {
     "duration": 28.730978,
     "end_time": "2024-05-21T10:08:17.706497",
     "exception": false,
     "start_time": "2024-05-21T10:07:48.975519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 10:07:50.733370: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-21 10:07:50.733472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-21 10:07:50.861541: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 45.5kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.99MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 57.9kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:14<00:00, 33.6MiB/s]\n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 2.16MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.45MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.22MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb3c4deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:17.816667Z",
     "iopub.status.busy": "2024-05-21T10:08:17.815516Z",
     "iopub.status.idle": "2024-05-21T10:08:17.821209Z",
     "shell.execute_reply": "2024-05-21T10:08:17.820166Z"
    },
    "papermill": {
     "duration": 0.062267,
     "end_time": "2024-05-21T10:08:17.823169",
     "exception": false,
     "start_time": "2024-05-21T10:08:17.760902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4fb4db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:17.934341Z",
     "iopub.status.busy": "2024-05-21T10:08:17.933465Z",
     "iopub.status.idle": "2024-05-21T10:08:17.939538Z",
     "shell.execute_reply": "2024-05-21T10:08:17.938609Z"
    },
    "papermill": {
     "duration": 0.063764,
     "end_time": "2024-05-21T10:08:17.941771",
     "exception": false,
     "start_time": "2024-05-21T10:08:17.878007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee8f446f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.051013Z",
     "iopub.status.busy": "2024-05-21T10:08:18.050428Z",
     "iopub.status.idle": "2024-05-21T10:08:18.055995Z",
     "shell.execute_reply": "2024-05-21T10:08:18.055134Z"
    },
    "papermill": {
     "duration": 0.062108,
     "end_time": "2024-05-21T10:08:18.057954",
     "exception": false,
     "start_time": "2024-05-21T10:08:17.995846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70a1b29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.169433Z",
     "iopub.status.busy": "2024-05-21T10:08:18.168749Z",
     "iopub.status.idle": "2024-05-21T10:08:18.175807Z",
     "shell.execute_reply": "2024-05-21T10:08:18.174871Z"
    },
    "papermill": {
     "duration": 0.065321,
     "end_time": "2024-05-21T10:08:18.177708",
     "exception": false,
     "start_time": "2024-05-21T10:08:18.112387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'ctx_len': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "771c644d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.290074Z",
     "iopub.status.busy": "2024-05-21T10:08:18.289116Z",
     "iopub.status.idle": "2024-05-21T10:08:18.295614Z",
     "shell.execute_reply": "2024-05-21T10:08:18.294667Z"
    },
    "papermill": {
     "duration": 0.064247,
     "end_time": "2024-05-21T10:08:18.297560",
     "exception": false,
     "start_time": "2024-05-21T10:08:18.233313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'ctx_len': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5821c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.407970Z",
     "iopub.status.busy": "2024-05-21T10:08:18.407141Z",
     "iopub.status.idle": "2024-05-21T10:08:18.411857Z",
     "shell.execute_reply": "2024-05-21T10:08:18.410886Z"
    },
    "papermill": {
     "duration": 0.062316,
     "end_time": "2024-05-21T10:08:18.413755",
     "exception": false,
     "start_time": "2024-05-21T10:08:18.351439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"ctx_len\": 1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ed156ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.524607Z",
     "iopub.status.busy": "2024-05-21T10:08:18.523725Z",
     "iopub.status.idle": "2024-05-21T10:08:18.528371Z",
     "shell.execute_reply": "2024-05-21T10:08:18.527351Z"
    },
    "papermill": {
     "duration": 0.062273,
     "end_time": "2024-05-21T10:08:18.530394",
     "exception": false,
     "start_time": "2024-05-21T10:08:18.468121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41aa7006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.642020Z",
     "iopub.status.busy": "2024-05-21T10:08:18.641176Z",
     "iopub.status.idle": "2024-05-21T10:08:18.647745Z",
     "shell.execute_reply": "2024-05-21T10:08:18.646852Z"
    },
    "papermill": {
     "duration": 0.063493,
     "end_time": "2024-05-21T10:08:18.649754",
     "exception": false,
     "start_time": "2024-05-21T10:08:18.586261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'ctx_len': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "797aacb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:18.759737Z",
     "iopub.status.busy": "2024-05-21T10:08:18.759339Z",
     "iopub.status.idle": "2024-05-21T10:08:20.491272Z",
     "shell.execute_reply": "2024-05-21T10:08:20.490261Z"
    },
    "papermill": {
     "duration": 1.790235,
     "end_time": "2024-05-21T10:08:20.493449",
     "exception": false,
     "start_time": "2024-05-21T10:08:18.703214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc1fc07f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:20.606845Z",
     "iopub.status.busy": "2024-05-21T10:08:20.605955Z",
     "iopub.status.idle": "2024-05-21T10:08:20.611329Z",
     "shell.execute_reply": "2024-05-21T10:08:20.610424Z"
    },
    "papermill": {
     "duration": 0.064301,
     "end_time": "2024-05-21T10:08:20.613175",
     "exception": false,
     "start_time": "2024-05-21T10:08:20.548874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6471dfc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:20.726071Z",
     "iopub.status.busy": "2024-05-21T10:08:20.725210Z",
     "iopub.status.idle": "2024-05-21T10:08:20.744117Z",
     "shell.execute_reply": "2024-05-21T10:08:20.743201Z"
    },
    "papermill": {
     "duration": 0.077608,
     "end_time": "2024-05-21T10:08:20.746096",
     "exception": false,
     "start_time": "2024-05-21T10:08:20.668488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    " \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    " \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    " \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    " \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    " \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b173de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:20.857868Z",
     "iopub.status.busy": "2024-05-21T10:08:20.857520Z",
     "iopub.status.idle": "2024-05-21T10:08:23.167145Z",
     "shell.execute_reply": "2024-05-21T10:08:23.165851Z"
    },
    "papermill": {
     "duration": 2.367659,
     "end_time": "2024-05-21T10:08:23.169266",
     "exception": false,
     "start_time": "2024-05-21T10:08:20.801607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " who are you? met PDT\u001f overcame cocktailsutsche rampantiscovery Cant milestones undesirable MunichByte belovedHoweverosph courageousnexpected Adelaide Elvis sheds Xer antibioticsReplaries\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"who are you?\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"ctx_len\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8abd7",
   "metadata": {
    "papermill": {
     "duration": 0.054342,
     "end_time": "2024-05-21T10:08:23.278993",
     "exception": false,
     "start_time": "2024-05-21T10:08:23.224651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Alternative Weight Loading from Hugging Face Model Hub using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "143e4b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:23.389821Z",
     "iopub.status.busy": "2024-05-21T10:08:23.389102Z",
     "iopub.status.idle": "2024-05-21T10:08:27.046760Z",
     "shell.execute_reply": "2024-05-21T10:08:27.045810Z"
    },
    "papermill": {
     "duration": 3.714907,
     "end_time": "2024-05-21T10:08:27.048817",
     "exception": false,
     "start_time": "2024-05-21T10:08:23.333910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f669ac2480046989d6138ab22a90ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8545b6376f7d4ae8898508b92e9aba11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "\n",
    "# allowed model names\n",
    "model_names = {\n",
    "    \"gpt2-small (124M)\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium (355M)\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"openai-community/gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"openai-community/gpt2-xl\"\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "gpt_hf = GPT2Model.from_pretrained(model_names[CHOOSE_MODEL], cache_dir=\"checkpoints\")\n",
    "gpt_hf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3cbf976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:27.161601Z",
     "iopub.status.busy": "2024-05-21T10:08:27.161267Z",
     "iopub.status.idle": "2024-05-21T10:08:27.167590Z",
     "shell.execute_reply": "2024-05-21T10:08:27.166702Z"
    },
    "papermill": {
     "duration": 0.064684,
     "end_time": "2024-05-21T10:08:27.169645",
     "exception": false,
     "start_time": "2024-05-21T10:08:27.104961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"ctx_len\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small\"\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1c526d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:27.281974Z",
     "iopub.status.busy": "2024-05-21T10:08:27.281059Z",
     "iopub.status.idle": "2024-05-21T10:08:27.286147Z",
     "shell.execute_reply": "2024-05-21T10:08:27.285284Z"
    },
    "papermill": {
     "duration": 0.063057,
     "end_time": "2024-05-21T10:08:27.288010",
     "exception": false,
     "start_time": "2024-05-21T10:08:27.224953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_check(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ac06f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:27.399467Z",
     "iopub.status.busy": "2024-05-21T10:08:27.398606Z",
     "iopub.status.idle": "2024-05-21T10:08:27.415504Z",
     "shell.execute_reply": "2024-05-21T10:08:27.414607Z"
    },
    "papermill": {
     "duration": 0.074747,
     "end_time": "2024-05-21T10:08:27.417530",
     "exception": false,
     "start_time": "2024-05-21T10:08:27.342783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_weights(gpt, gpt_hf):\n",
    "\n",
    "    d = gpt_hf.state_dict()\n",
    "\n",
    "    gpt.pos_emb.weight = assign_check(gpt.pos_emb.weight, d[\"wpe.weight\"])\n",
    "    gpt.tok_emb.weight = assign_check(gpt.tok_emb.weight, d[\"wte.weight\"])\n",
    "    \n",
    "    for b in range(BASE_CONFIG[\"n_layers\"]):\n",
    "        q_w, k_w, v_w = np.split(d[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign_check(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign_check(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign_check(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split(d[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign_check(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign_check(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign_check(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "    \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign_check(gpt.trf_blocks[b].att.out_proj.weight, d[f\"h.{b}.attn.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign_check(gpt.trf_blocks[b].att.out_proj.bias, d[f\"h.{b}.attn.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign_check(gpt.trf_blocks[b].ff.layers[0].weight, d[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign_check(gpt.trf_blocks[b].ff.layers[0].bias, d[f\"h.{b}.mlp.c_fc.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign_check(gpt.trf_blocks[b].ff.layers[2].weight, d[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign_check(gpt.trf_blocks[b].ff.layers[2].bias, d[f\"h.{b}.mlp.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].norm1.scale = assign_check(gpt.trf_blocks[b].norm1.scale, d[f\"h.{b}.ln_1.weight\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign_check(gpt.trf_blocks[b].norm1.shift, d[f\"h.{b}.ln_1.bias\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign_check(gpt.trf_blocks[b].norm2.scale, d[f\"h.{b}.ln_2.weight\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign_check(gpt.trf_blocks[b].norm2.shift, d[f\"h.{b}.ln_2.bias\"])\n",
    "    \n",
    "        gpt.final_norm.scale = assign_check(gpt.final_norm.scale, d[f\"ln_f.weight\"])\n",
    "        gpt.final_norm.shift = assign_check(gpt.final_norm.shift, d[f\"ln_f.bias\"])\n",
    "        gpt.out_head.weight = assign_check(gpt.out_head.weight, d[\"wte.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25cc4a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:27.529472Z",
     "iopub.status.busy": "2024-05-21T10:08:27.529002Z",
     "iopub.status.idle": "2024-05-21T10:08:30.014663Z",
     "shell.execute_reply": "2024-05-21T10:08:30.013588Z"
    },
    "papermill": {
     "duration": 2.544668,
     "end_time": "2024-05-21T10:08:30.017192",
     "exception": false,
     "start_time": "2024-05-21T10:08:27.472524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/3877979348.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.nn.Parameter(torch.tensor(right))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(gpt, gpt_hf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d494c08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:08:30.130744Z",
     "iopub.status.busy": "2024-05-21T10:08:30.130035Z",
     "iopub.status.idle": "2024-05-21T10:08:43.990890Z",
     "shell.execute_reply": "2024-05-21T10:08:43.989472Z"
    },
    "papermill": {
     "duration": 13.919721,
     "end_time": "2024-05-21T10:08:43.993113",
     "exception": false,
     "start_time": "2024-05-21T10:08:30.073392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " সরকারি হিসাবে বাংলাদেশের বর্তমান মাথপিছু আয় ২,৭৮৪ মার্কিন ডলার !! বর্তমান মার্কিন মার্কিন �\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"সরকারি হিসাবে বাংলাদেশের বর্তমান মাথপিছু আয় ২,৭৮৪ মার্কিন ডলার !!\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"ctx_len\"],\n",
    "    top_k=1,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd1796",
   "metadata": {
    "papermill": {
     "duration": 0.056102,
     "end_time": "2024-05-21T10:08:44.108321",
     "exception": false,
     "start_time": "2024-05-21T10:08:44.052219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5039258,
     "sourceId": 8455276,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5045113,
     "sourceId": 8463029,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 216.370924,
   "end_time": "2024-05-21T10:08:47.870212",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-21T10:05:11.499288",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "17cfda1907af49519f97a5cda7f0e91a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2acf0cec070c46aca728e6400de821e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "45e31e5f31884689bc536f2d379c2169": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "478fd02f1a444ca8a25bbd3e86fc0167": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff1b52f3a097424087c3979bd7183d6d",
       "placeholder": "​",
       "style": "IPY_MODEL_80d19f815bda4d299e7da0992fef885a",
       "value": " 665/665 [00:00&lt;00:00, 47.7kB/s]"
      }
     },
     "5334c6ba0d69426c9a4bdf78abf2554d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f6d5a4ae2724d108999769de5fde778",
       "placeholder": "​",
       "style": "IPY_MODEL_45e31e5f31884689bc536f2d379c2169",
       "value": "config.json: 100%"
      }
     },
     "585c1331df8a477391e66ba468e7556b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5c2c61a9d4b4455f953121896bf99314": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8ef78399f3343ada9d0fae78bfcbdad",
       "max": 665.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2acf0cec070c46aca728e6400de821e3",
       "value": 665.0
      }
     },
     "5f6d5a4ae2724d108999769de5fde778": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67c4717869e1482b87c0778f467dc568": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80d19f815bda4d299e7da0992fef885a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8545b6376f7d4ae8898508b92e9aba11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4a4021c145049b5a8e04bf74568861e",
        "IPY_MODEL_a08d6d3bd1f84ee3aa7a45eed34652b8",
        "IPY_MODEL_f4cb2e03990c4baca06df62361116078"
       ],
       "layout": "IPY_MODEL_e51ededa848a4643a941a0d7bda8e333"
      }
     },
     "878270b8f300434f80e08314489fd0f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f669ac2480046989d6138ab22a90ce3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5334c6ba0d69426c9a4bdf78abf2554d",
        "IPY_MODEL_5c2c61a9d4b4455f953121896bf99314",
        "IPY_MODEL_478fd02f1a444ca8a25bbd3e86fc0167"
       ],
       "layout": "IPY_MODEL_67c4717869e1482b87c0778f467dc568"
      }
     },
     "a08d6d3bd1f84ee3aa7a45eed34652b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e2d2474274114546a4fff0b67dc96819",
       "max": 548105171.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_585c1331df8a477391e66ba468e7556b",
       "value": 548105171.0
      }
     },
     "a4a4021c145049b5a8e04bf74568861e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b02ea7919b974e2dbd0f9ee36019d9df",
       "placeholder": "​",
       "style": "IPY_MODEL_dc4939f8e5d144f1a5c6dd23a46ed7e8",
       "value": "model.safetensors: 100%"
      }
     },
     "a8ef78399f3343ada9d0fae78bfcbdad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b02ea7919b974e2dbd0f9ee36019d9df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc4939f8e5d144f1a5c6dd23a46ed7e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e2d2474274114546a4fff0b67dc96819": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e51ededa848a4643a941a0d7bda8e333": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4cb2e03990c4baca06df62361116078": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_878270b8f300434f80e08314489fd0f2",
       "placeholder": "​",
       "style": "IPY_MODEL_17cfda1907af49519f97a5cda7f0e91a",
       "value": " 548M/548M [00:02&lt;00:00, 307MB/s]"
      }
     },
     "ff1b52f3a097424087c3979bd7183d6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
